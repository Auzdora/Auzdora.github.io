<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Query Execution</title>
      <link href="/2023/07/17/QueryExecution/"/>
      <url>/2023/07/17/QueryExecution/</url>
      
        <content type="html"><![CDATA[<blockquote><p>在完成bustub的project 3 query execution时，需要阅读大量的源码，并且尝试理清每一个系统组件之间的关系。在这篇博客中，从execution层的视角之下，记录一下bustub的execution engine的执行架构。在execution层之上的parser，binder，planner以及optimizer层，仅在必要时提及，详细对这些层的解析会在之后的博客中记录。</p></blockquote><h2 id="Overview-on-top-of-execution-layer"><a href="#Overview-on-top-of-execution-layer" class="headerlink" title="Overview on top of execution layer"></a>Overview on top of execution layer</h2><p>官方网站的project 3的handout中，在背景部分详细介绍了每一个project在bustub架构中的位置。在进入execution layer之前，简要理解前面几层的作用也是重要的。在execution layer之上，存在parser，binder，planner以及optimizer四层。这四层总体的作用可以描述为一句话：SQL语言通过解析、语法检查，绑定bustub内部object后，根据SQL语义构建execution plan并优化。优化过后的plan递交给execution engine，执行并返回对应的结果。</p><h3 id="Parser-amp-Binder"><a href="#Parser-amp-Binder" class="headerlink" title="Parser &amp; Binder"></a>Parser &amp; Binder</h3><p>Bustub的parser利用了duckdb的源码，将一个query输入到parser中，会对其进行解析和保存，生成一个AST（Abstract Syntax Tree）保存下来。Binder将绑定对应的statement。最后将statement提交到planner中。</p><h3 id="Planner"><a href="#Planner" class="headerlink" title="Planner"></a>Planner</h3><p>Planner负责对statement语句进行规划，将statement链接为一个plan node tree，并在plan node中加入必要的信息。</p><h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><p>Optimizer对生成好的plan tree进行评估并优化，返回一个优化后的plan tree。最终提交给Execution engine。</p><p><strong>Tips</strong>：在阅读源码时，可以根据<code>bustub_instance.cpp</code>这个文件来看。shell.cpp封装了bustub instance，并在shell中调用ExecuteSql，对string的sql进行解析，规划，优化以及执行等一系列操作。做project 3的过程中也可以根据bustub instance进行debug，会很快发现问题的原因。</p><h2 id="Overview-of-execution-layer"><a href="#Overview-of-execution-layer" class="headerlink" title="Overview of execution layer"></a>Overview of execution layer</h2><p>了解了上面四层的基本作用和功能后，我们就可以将他们所有的细节和实现抛之脑后，并专注于optimizer给我们提供了什么。Optimizer返回的是一个plan node。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Database Management System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Query Processing</title>
      <link href="/2023/07/01/QueryProcessing/"/>
      <url>/2023/07/01/QueryProcessing/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Query Processing指的是从数据库抽取数据的一系列活动。是用户和物理存储底层交互的中间层，其中包含三个阶段：</p><ul><li><strong>解析和翻译（Parsing &amp; translation）</strong>：解析用户的意图（通过构造Abstract Syntax Tree），并与DBMS内部的数据结构相对应（通过binder）然后进行翻译</li><li><strong>优化（Optimization）</strong>：对Query流程进行优化，找到开销最小的执行</li><li><strong>评估（Evaluation）</strong>：对一个Query会有不同的优化结果，定量评估其开销</li></ul></blockquote><p>我们可以先对这三个阶段在high-level的角度理解，之后在深入到具体的算法细节。</p><h2 id="High-level-Overview"><a href="#High-level-Overview" class="headerlink" title="High-level Overview"></a>High-level Overview</h2><p>一个Query在执行之前，需要先转化为系统理解的方式。SQL语句是声明式语言，意思就是仅仅告诉DBMS我需要什么数据。这就需要DBMS把如何获取数据、哪种方式最优等等这一系列问题隐藏起来，并自动的选取开销最小的方式（最优）执行，以便用户能最快最准确的拿到他想要的结果。</p><p>用户输入SQL语句后，首先做的就是解析。让DBMS明白这个query的语义。在这过程中，解析器会做一些检查，比如用户的句法是否被DBMS定义、是否正确、是否能在DBMS中找到对应的数据结构等等。构建AST之后，它便会将其翻译成关系代数表达式，方便后续的优化。</p><p>给定一个AST后，用户的一个Query可以被翻译为不同的关系代数表达式。而每一个表达式中的操作算子又可以采用很多种不同的算法实现。因此，如果想评估一个query，我们不仅仅需要关系代数表达式，还需要标注一些评估算子开销的必要信息。一个标有相关信息的关系代数算子成为evaluation primitive；一系列被标注的算子构成的query关系代数表达式被称为一个query plan。</p><p>优化的目的就是从很多种query plan中找到开销最小的plan，并把plan送给execution engine执行。</p><p>下图是书“Database System Concepts”中的图，可以更好的理解Query Processing在数据库中的流程：</p><p><img src="query1.png" alt=""></p><h2 id="Measures-of-Query-Cost"><a href="#Measures-of-Query-Cost" class="headerlink" title="Measures of Query Cost"></a>Measures of Query Cost</h2><p>我们知道，对于一个query，可能会有很多不同的query plan。问题在于，我们如何从不同的plan中寻找出最优的方法去执行呢？和深度学习一样，我们需要某种evaluation的方法，或者说benchmark。思路是，利用这些评估标准，计算每一个plan中每一个算子的开销，把一个plan的所有算子开销加起来，对比不同plan的结果。</p><p>评估的方式可以根据不同的硬件资源来决定，比如：</p><ul><li>硬盘访问时间</li><li>CPU执行时间</li><li>在分布式数据库中，数据交换的时间</li></ul><p>在早些年的数据库系统中，由于大量的数据存储在磁盘上，因此IO cost占据主要位置。但随着固态硬盘的出现，存取速度快了很多，因此不得不考虑CPU执行的速度。不过，CPU执行时间相对简单，很好计算，只需要提前设置一些参数就能完成，因此在衡量query cost的过程中主要还是对IO存取进行考虑。</p><p>我们用block转移数量（the number of blocks transferred）和随机IO访问量（the number of random IO access）作为两个重要的评估参数。如果需要平均$t_T$秒从磁盘转移一个block数据，平均$t_S$秒随机读取一个block，那么如果转移b个block和进行S次随机访存需要$b <em> t_T+S</em>t_S$秒。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Database Management System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cast_in_cpp</title>
      <link href="/2023/06/23/cast-in-cpp/"/>
      <url>/2023/06/23/cast-in-cpp/</url>
      
        <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote><p>在用C++写一些Lab和项目的时候，涉及到cast在C++里的应用。发现自己并不熟悉这些东西，于是也仅仅在阅读一些博客后草草了事，没有很深的记忆。但是过一段时间之后，又全部都忘记了，所以想写一个博客来记录一下加深自己的理解。</p></blockquote><p>C++是一种强类型语言，当需要把一个变量按照使用需求转化为另一个变量的时候，就需要用到类型转换。C++提供了四种类型转换的方法：</p><ul><li>static_cast</li><li>dynamic_cast</li><li>reinterpret_cast</li><li>const_cast</li></ul><p>下面我们一个个的理解它们。</p><h2 id="static-cast"><a href="#static-cast" class="headerlink" title="static_cast"></a>static_cast</h2><p>Static_cast是在C++中最常用的casting方法。它可以用来在不同相关类型间做转换，例如数值类型（int，float）或者在父子类中转换。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">int</span> a <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span><span class="token keyword">float</span> b <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面是简单的数值类型转换，替换了之前的隐式转换。</p><p>下面通过一个例子说明class类型。</p><p>假设有一个父类class animal，两个继承animal的子类dog和cat，代码如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Animal</span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"The animal makes a sound\n"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Dog</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Animal</span></span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">void</span> <span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">override</span> <span class="token punctuation">&#123;</span> std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"The dog barks\n"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>    <span class="token keyword">void</span> <span class="token function">wagTail</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"The dog wags its tail\n"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Cat</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Animal</span></span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">void</span> <span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">override</span> <span class="token punctuation">&#123;</span> std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"The cat meows\n"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span>    <span class="token keyword">void</span> <span class="token function">purr</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span> std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"The cat purrs\n"</span><span class="token punctuation">;</span> <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在我们来看看如何使用<code>static_class</code>。</p><ol><li><p>Upcasting：Upcasting是将指向子类的指针转化为指向父类的指针，这样的操作在C++中是认为安全的。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">Dog<span class="token operator">*</span> dog <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Dog</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Animal<span class="token operator">*</span> animal <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>Animal<span class="token operator">*</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>dog<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Upcasting</span>animal<span class="token operator">-></span><span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Outputs: "The dog barks"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><ol><li><p>Downcasting：Downcasting相反，将指向父类的指针指向子类。这是一种不安全的操作，因为父类的object可能并不是子类的object，这时候调用子类的object就会出现Undefined behavior。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">Animal<span class="token operator">*</span> animal <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Animal</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Dog<span class="token operator">*</span> dog <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dog<span class="token operator">*</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>animal<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Unsafe downcasting</span>dog<span class="token operator">-></span><span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Undefined behavior!</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>安全的downcasting是这样的：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp">Animal<span class="token operator">*</span> animal <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Dog</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// The Animal is actually a Dog</span>Dog<span class="token operator">*</span> dog <span class="token operator">=</span> <span class="token generic-function"><span class="token function">static_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>Dog<span class="token operator">*</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>animal<span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Safe downcasting</span>dog<span class="token operator">-></span><span class="token function">makeSound</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Outputs: "The dog barks"</span>dog<span class="token operator">-></span><span class="token function">wagTail</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// Outputs: "The dog wags its tail"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这个例子中，animal变量本质就是Dog，因此downcasting为Dog类型就可以使用对应的函数。</p></li></ol><h2 id="dynamic-cast"><a href="#dynamic-cast" class="headerlink" title="dynamic_cast"></a>dynamic_cast</h2><p><code>dynamic_cast</code>主要用于类的downcasting和upcasting。这种cast会在runtime动态检查，在upcasting时，这种是更加安全的操作，效果与<code>static_cast</code>类似。但是在downcasting时，<code>dynamic_cast</code>会对其进行安全检查，这时后会访问父类的虚函数表（只有父类定义了虚函数才有虚函数表，有虚函数说明具有父类转换子类的需求和能力），如果没有虚函数表或没找到相关的信息，或者object不是目标类型，动态检查会失败，即返回一个nullptr。</p><p><strong>Note</strong>：要使用<code>dynamic_cast</code>，且downcasting时，必须父类拥有虚函数。</p><p>下面是使用<code>dynamic_cast</code>的例子：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Base</span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">virtual</span> <span class="token keyword">void</span> <span class="token function">foo</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>  <span class="token comment">// Making this class polymorphic</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span class="token keyword">class</span> <span class="token class-name">Derived</span> <span class="token operator">:</span> <span class="token base-clause"><span class="token keyword">public</span> <span class="token class-name">Base</span></span> <span class="token punctuation">&#123;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token keyword">void</span> <span class="token function">bar</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span>Base<span class="token operator">*</span> basePtr <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Derived</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>Derived<span class="token operator">*</span> derivedPtr <span class="token operator">=</span> <span class="token generic-function"><span class="token function">dynamic_cast</span><span class="token generic class-name"><span class="token operator">&lt;</span>Derived<span class="token operator">*</span><span class="token operator">></span></span></span><span class="token punctuation">(</span>basePtr<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>derivedPtr<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    derivedPtr<span class="token operator">-></span><span class="token function">bar</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个例子中，Base是基类且有虚函数，Derived是派生类。</p><h2 id="reinterpret-cast"><a href="#reinterpret-cast" class="headerlink" title="reinterpret_cast"></a>reinterpret_cast</h2><p>Reinterpret_cast不会在cast过程中进行安全检查，需要程序员在使用的时候格外小心。理解起来较为方便，首先把某个数据或者object当作内存里的一块01组成的block。接下来，在做reinterpret cast的时候，本质就是在这个block之上加入不同的看待这个block的视角。我可以cast为int，那么使用的时候就被解释为int，我可以cast到一个class，那么使用的时候就被解释为一个class。</p><p>给予最大的自由，不加繁琐的限制，至于安全问题交给程序员来操心。</p><h2 id="const-cast"><a href="#const-cast" class="headerlink" title="const_cast"></a>const_cast</h2><p><strong>🚧(building…)🚧</strong></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>BatchNorm vs LayerNorm</title>
      <link href="/2023/06/13/BatchNorm-LayerNorm/"/>
      <url>/2023/06/13/BatchNorm-LayerNorm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近在复习之前学过的Transformer的底层原理，又一次碰到了LayerNorm。之前在做一些深度估计项目的时候，使用ViT架构，也用到了LayerNorm。但仅仅将它作为了一个黑箱，并没有深刻的理解它的原理。而且与LayerNorm对应的BatchNorm，虽然之前阅读过原论文，但仍处于一知半解的阶段，大部分也忘记了。借助这个blog，重新学习和回忆一下。并对比两者的不同，并动手实现相应的模块。</p></blockquote><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>训练一个神经网络其实是比较困难的，因为神经网络的学习过程是<strong>反向传播（Back-propagation）</strong>：通过<strong>梯度下降（Gradient Descent）</strong>的方式一步步反向更新每一个神经元的权重。而且神经网络一般由多个层构成。这样就造成了一个问题，假设我们有A，B两层神经网络。A的输入是x，输出是y，B的输入是y，输出是z。计算与标签的损失，求梯度进行反向传播之后，A变成了A‘，B变成了B’。再向A输入x，得到的就再也不是y了，而可能是k。这时对于B而言，它之前所学到的关于y的信息就不适用了，必须重新进行adaptation。这样的现象叫做<strong>Internal covariate shift</strong>。这也是提出Batch Normalization的作者的动机。</p><p>但Santurkar等人的工作How Does Batch Normalization Help Optimization中指出，使得Batch Normalization成功的原因并非因为Internal covariate shift，甚至在某种情形下BatchNorm没有减少internal covariate shift。这篇blog不讨论谁的观点绝对正确，仅仅对BatchNorm的思想做总结。</p><h3 id="Why-Batch-Normalization"><a href="#Why-Batch-Normalization" class="headerlink" title="Why Batch Normalization"></a>Why Batch Normalization</h3><p><strong>一定程度消除Internal covariate shift</strong>：在introduction部分讲述了什么是internal covariate shift（ICS）。ICS导致每一层在更新参数后重新适应新的输入的变化，降低了学习的效率。采用BatchNorm，将输入归一化为均值为0和方差为1的数据，不仅仅可以一定程度解决梯度消失问题（不归一化数值会进入saturated zone，就是非线性激活函数的两端），还能使不同层之间近乎于独立学习，降低了层与层之间的耦合性。</p><p><strong>BatchNorm的平滑效应</strong>：BatchNorm将优化问题的landscape从“很瘦长的椭圆”转换为更平滑和对称的正圆（提升了损失函数的Lipschitzness和其梯度的Lipschitzness，关于Lipschitzness还在补充）。确保了问题的平滑性，就减少了初始值和学习率对神经网络的影响。我们可以采用更大的学习率加速网络学习，不必太过担心网络进入局部极小值。</p><h3 id="Mathematical-Description"><a href="#Mathematical-Description" class="headerlink" title="Mathematical Description"></a>Mathematical Description</h3><p>假设对一个layer的输入是$\vec x = (x^{ (1) } … x^{ (d) })$，那么对这个输入的归一化如下：</p><script type="math/tex; mode=display">\hat{x}_i ^{ (k) } = \frac{x_i^{ (k) } - E[x^{ (k) } ]} {\sqrt{Var[x ^{ (k) } ] + \epsilon}}</script><p>其中</p><script type="math/tex; mode=display">E[x^{ (k) } ] = \frac{1} {m} \sum_{i=1} ^{m} x_i ^{ (k) }</script><script type="math/tex; mode=display">Var[x^{ (k) } ] = \frac{1} {m} \sum_{i=1} ^{m} ( x_i ^{ (k) } - E[x^{ (k) } ] )</script><p>$m$表示mini-batch的batch size，$k$表示输入的第几个特征。</p><p>但如果就这样硬生生将每一层的activation后的输出归一化的话，会让模型丧失原有的表达能力。以下是ChatGPT的回答：</p><blockquote><p>The linear transformation process in Batch Normalization, which involves the learnable parameters (scale factor $\gamma$ and shift $\beta$), is crucial for the following reasons:</p><ol><li><p><strong>Restoring the Representational Power of the Network</strong>: After applying Batch Normalization, the activations of the layer are normalized to have zero mean and unit variance. While this normalization process helps to stabilize learning and reduce internal covariate shift, it can also limit what the layer can represent. For instance, in some cases, the network might learn that the best representation of the data for the subsequent layers is not zero-mean/unit-variance. The scale and shift transformation allows the network to learn the most suitable scale and location of the activations, thereby restoring the representational power of the network.</p></li><li><p><strong>Preserving the Expressive Power of Activation Functions</strong>: Certain activation functions like ReLU and its variants have different behaviors in different regions of the input space. For instance, the ReLU function is sensitive to positive inputs and insensitive to negative inputs. If Batch Normalization is used without the scale and shift, the activations would be mostly confined to the region where ReLU is active, thereby limiting the expressive power of the activation function. The scale and shift transformation allows the network to learn to use the full expressive power of the activation function.</p></li><li><p><strong>Flexibility</strong>: The learnable parameters $\gamma$ and $\beta$ provide the network with the flexibility to learn the optimal scale and mean of the activations. If the optimal scale and mean are indeed 1 and 0 respectively, the network can learn γ close to 1 and β close to 0. But if they are not, the network has the flexibility to learn other values.</p></li></ol><p>In summary, the linear transformation process in Batch Normalization, governed by the learnable parameters $\gamma$ and $\beta$, is crucial for preserving the expressive power of the network and providing it with the flexibility to learn the most suitable representations.</p></blockquote><p>因此在归一化之后，需要加入两个可学习的参数，给予模型自由学习的能力。让其在学习的过程中自己寻找最适合的分布状态。其数学描述为：</p><script type="math/tex; mode=display">y_i ^{ (k) } = \gamma^{ (k) } \hat{x}_i ^{ (k) } + \beta ^ { (k) }</script><p>在训练阶段，BatchNorm按照上述的数学描述进行学习。</p><p>但在验证和测试阶段，BatchNorm则有所不同。因为在训练阶段，我们是以mini-batch的形式将数据喂入模型的。训练过程中，会实时计算mini-batch的均值和方差。而如果在测试阶段也这样做，尤其是每次输入一个测试数据的时候，mini-batch的size是1，最后会得0。这显然是不合理的。因此在工程上，采用running mean和running variance的方法，会在训练阶段实时更新。</p><p>更新过程为：</p><script type="math/tex; mode=display">E[x^{ (k) } ]' = momentum \times E[x^{ (k) } ]' + (1 - momentum) \times E[x^{ (k) } ]</script><script type="math/tex; mode=display">Var[x^{ (k) } ]' = momentum \times Var[x^{ (k) } ]' + (1 - momentum) \times Var[x^{ (k) } ]</script><h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><p>加速神经网络训练的方法可以用之前提到的batch normalization。但是有两点需要注意：</p><ul><li>Batch normalization比较依赖于mini-batch的大小，mini-batch越大，batch norm的效果越好</li><li>Batch normalization似乎对于RNN这种处理sequence数据的模型适用难度较高</li></ul><p>基于这两点因素，作者提出了Layer Normalization。</p><h3 id="Why-Layer-Normalization"><a href="#Why-Layer-Normalization" class="headerlink" title="Why Layer Normalization"></a>Why Layer Normalization</h3><ul><li>因为Batch normalization使用的方差和均值是基于mini-batch对整体的估计，这说明其受限于mini-batch的大小。</li><li>Batch normalization在序列模型中不太适用，因为序列模型的输入经常是变长的。</li></ul><h3 id="Mathematical-Description-1"><a href="#Mathematical-Description-1" class="headerlink" title="Mathematical Description"></a>Mathematical Description</h3><p>假设对一个layer的输入是$\vec x = (x^{ (1) } … x^{ (d) })$，那么对这个输入的归一化如下：</p><script type="math/tex; mode=display">\hat{x} ^{ (k) } = \frac{x ^{ (k) } - E[\vec x]} {\sqrt{Var[\vec x] + \epsilon}}</script><p>其中</p><script type="math/tex; mode=display">E[\vec x] = \frac{1} {d} \sum_{k = 1} ^ {d} x ^ { (k) }</script><script type="math/tex; mode=display">Var[\vec x] = \frac{1} {d} \sum_{k=1} ^{d} ( x ^{ (k) } - E[\vec x] )</script><p>为了保留模型的表达能力，还是加入两个可学习的参数做一个线性变换。</p><script type="math/tex; mode=display">y ^{ (k) } = \gamma^{ (k) } \hat{x} ^{ (k) } + \beta ^ { (k) }</script><p>Layer Normalization的训练和测试阶段的行为一直，因此不需要额外加入其他变量来做记录。仅需要在推理的时候，计算输入数据的均值和方差就可以。</p><h3 id="Batch-vs-Layer"><a href="#Batch-vs-Layer" class="headerlink" title="Batch vs Layer"></a>Batch vs Layer</h3><ul><li>Batch normalization受mini-batch size的影响，size越小，计算出的batch statistics越不能代表整体。而Layer normalization与batch的大小是独立的。</li><li>Layer normalization更适合用于sequence model，处理变长数据。</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>Batch Normalizaiton: Accelerating Deep Network Training by Reducing Internal Covariate Shift</li><li>How Does Batch Normalization Help Optimization</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning Optimization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Life Blog - Trip to Qingdao</title>
      <link href="/2023/06/11/Life-001/"/>
      <url>/2023/06/11/Life-001/</url>
      
        <content type="html"><![CDATA[<blockquote><p>因为疫情的原因，19年上大学的我整整三年没有怎么出去旅行。大四下学期是一个比较惬意的时候，没有繁琐的课程、需要参加的活动等等，时间相对空闲。也算是弥补一下前三年的遗憾，赶着毕业前，去一趟青岛和蓬莱。</p></blockquote><h2 id="01-前言"><a href="#01-前言" class="headerlink" title="01 前言"></a>01 前言</h2><p>还是花了一些时间规划的。对于像我这样的穷游党而言，主要的开销就是出行和住宿。刚开始制定的旅游计划相当极限，青岛、烟台、蓬莱和济南要在五天四夜之间全部游览完。有两天晚上都需要在火车上度过，尤其是返程上海时，凌晨2点的普快，一直要坐到第二天12点… 来回往复并算上中间所有旅游地点的车费，大约需要1.5k。</p><p>后来听取了一些同学的建议，去掉了济南的行程。在青岛呆两天半，第四天早上青岛北站出发到蓬莱，当天下午六点从蓬莱出发到烟台。烟台游玩一天，第六天返程。出行所需的费用被优化到了700块。大成功哈哈哈🤣。</p><p>自己非常喜欢旅游，因为小时候旅游带给我的感觉是全身心的放松。处于与自己生活环境截然不同的地方，暂时抛去学习和日常生活，去短暂感受没有任何枷锁束缚的舒畅。</p><h2 id="02-青岛🍾"><a href="#02-青岛🍾" class="headerlink" title="02 青岛🍾"></a>02 青岛🍾</h2><h3 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h3><p>去了青岛的第一天已经到了下午了，由于比较累，直接在住的酒店睡了一下午。当天没有任何行程。</p><h3 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h3><p>当然在第一天也不是什么都没干。在床上躺着的时间整理了一下需要去的景点。整理景点的时候才发现，订酒店订的位置在青岛市市北… 而青岛几乎所有景点都在市南的沿海。</p><p>旅游的路线是从西向东规划的。第一天要去的地方是：</p><ul><li>栈桥</li><li>海军博物馆</li><li>小青岛公园</li><li>小鱼山公园</li></ul><p>栈桥就是在青岛市西南侧的一个小角落，栈桥右侧是布满礁石的海滩，而左侧是细石沙。它的尽头有立着回澜阁。通过照片能看出来今天不适合旅游，肉眼可见的大雾，直接压在头顶上，把每一个高楼的头部擦除。</p><p><img src="qd1.png" alt=""></p><p>中午去吃了一碗面，20元…，没吃饱又点了一个夹肉馍，说实话不太好吃，但要10块。一顿饭30，让我第一次觉得青岛的物价也可以赶超上海（有可能是景点附近缘故？）。吃饭的附近还有个church。</p><p>从吃饭的地方坐几分钟公交就到了海军博物馆，去里面浏览了一些海军的历史和展出的物品，也去海军博物馆后面的两艘舰上绕了一圈。从舰上可以看到小青岛公园。不得不说沿海各个景点离的是真近。</p><p><img src="qd2.png" alt=""></p><p>小青岛绕着海边走了走，海浪拍击在石头上的声音很清脆，海风也很大。走到海边会感觉很冷，走到不靠海的地方又马上热了起来。</p><p><img src="qd3.png" alt=""></p><p>下午快四五点到了小鱼山山顶，据说这里可以一览无余青岛市，可以欣赏大海，也可以看城市的建筑风格。这时，大雾的伏笔显现了…</p><p><img src="qd4.png" alt=""></p><p>晚上我去见了在青岛上学的同学，一起吃了一顿烧烤后去五四广场和奥帆中心看了一眼。这个时候的大雾沉到地面上，和下雨一样，走了一圈直接浑身湿掉了。</p><p><img src="qd5.png" alt=""></p><p>完全什么都看不见。</p><p>End of this day.</p><h3 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h3><p>第三天似乎是对第二天糟糕天气的补偿，天气格外的好。乘坐青岛3号线地铁继续前往海边的景点，先去了第二浴场。人还是相当的多，在青岛这个旅游城市，我想“一个人漫步在海边沙滩上”这样的场景在全年都没办法找到几个时间节点吧😭。</p><p>今天的旅途还算简单，但是特别累。到达第二浴场也快中午了，在沙滩上捏了把十年没捏过的沙子，海的气味和沙子的触感直接把我拉回到十岁出头的时候在山东日照生活了一个月的日子。那时候热播一个电视剧，具体什么名字忘记了，是一个透明人小玩具，主角把它当作手机，然后可以召唤出一个红衣的有特异功能的女生。在日照的时候，不出门在家的时间大多数是在看剧和cosplay剧中的角色。<br><img src="qd6.png" alt=""></p><p>参观完第二浴场就一直沿着海边的路走，很废腿的一段路。有n多对新人在这里拍婚纱照。还有很长一段路里面飞满了白色的小飞虫，走一会儿就能爬满一身，为了防止吸进嘴里，这段路基本都戴了口罩🥲。<br><img src="qd7.png" alt=""></p><p>走着走着又找到一个绝美拍照的地方，但这里有栏杆，还写着不让跨越注意安全。我还是跨进去了，这是右很多黄色岩石组成的地方。远处可以看到奥帆中心，海上还时不时有帆船飘过。耳边充斥着海拍击在石头的声音。远处的城市在这个视角下若隐若现。我还专门录了一段视频说着“Look at this, this is so amazing!”来表达我此时的心情。<br><img src="qd8.png" alt=""></p><p>然后就是继续沿着海边走，夕阳已经快落山了。</p><p>到达第三浴场（大概）。这个浴场和不远处的城市接轨，显得有点突兀，但却又很和谐。傍晚这边有很多唱歌的人开直播，走累了坐在沙滩的台阶上，快落山的太阳把海面染成金黄色。</p><p>晚上的月亮也很远，到了五四广场。买了点淀粉肠和CoCo充饥。简要逛了一下就去了台东步行街。<br><img src="qd9.png" alt=""></p><p>End of this day.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Life Blog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Workflow in the era of LLM</title>
      <link href="/2023/05/27/LLM/"/>
      <url>/2023/05/27/LLM/</url>
      
        <content type="html"><![CDATA[<blockquote><p>在大语言模型时代，我们的学习和工作方式都有了很大的变化。依赖于生成式AI的强大能力，当前的LLM已经成为了各种APP、甚至操作系统的一部分。ChatGPT以及new bing的出现，展现出LLM的可能性。在写代码、学习新知识、撰写文档、归纳总结、阅读文献等众多任务中，可以成为很智能的Copilot。</p><p>之前学习的流程十分的复杂，东一块西一块，被各种所谓的“生产力”APP迷的眼花缭乱。我觉得也是时候总结一个对我而言高效的学习流程了。这篇博客主要以我为视角，介绍了我的生产力模型。</p></blockquote><h2 id="Study-Flow"><a href="#Study-Flow" class="headerlink" title="Study Flow"></a>Study Flow</h2><p><img src="Flow.png" alt=""></p><p>StudyFlow主要分为四个部分：Collector，Processor，Maintainer以及Scheduler。下面首先对各个部分做介绍，然后再整体叙述整个流程。</p><h3 id="Collector"><a href="#Collector" class="headerlink" title="Collector"></a>Collector</h3><p>这一部分是收集器，收集信息来源的两个主要方面就是利用Google搜索引擎和New bing搜索引擎。首先对于一些想要了解的问题，可以先咨询New bing，让其对网络的信息进行过滤，对提供的网页链接快速浏览。也可以用Google和new bing作为纯搜索引擎。</p><p>Collector中检索出的信息分为三类：</p><ul><li>流媒体视频信息：包括自媒体视频、网络公开课。此类信息是经过他人理解转述的信息。理解难度低，信息准确度不高。</li><li>博客、文章信息：是相对于视频动态信息的静态信息。也是经过他人理解转述的信息。理解难度低，但信息准确度不高。</li><li>Paper、书籍、代码信息：相对于前两者，此类信息更权威、更精确和精准。理解难度高，信息准确度高。</li></ul><p>针对前两类信息（流媒体和博客），由于理解难度低，在深入学习一个问题之前，可以先检索类似的信息。通过观看视频和阅读博客，对将要学习的内容建立起感性全局的认知，这些信息可以先缓存到Maintainer的ICU（Information Cache Unit）中，在每日的总结和回顾中将有用的信息维护进KMU）。</p><p>对于Paper、书籍、代码类的信息：该类信息理解难度高，处理起来费时费力。保存到icloud中，便于跨平台检索。</p><h3 id="Processor"><a href="#Processor" class="headerlink" title="Processor"></a>Processor</h3><p>信息处理器。主要靠自己的理解和ChatGPT的辅助。对于ChatGPT而言，在编程和相关技术领域的回答还是比较正确的，当然不排除胡诌的可能性，需要通过实验和对比网上的问题进一步验证。遇到一些细节问题，可以将ChatGPT作为一个耐心的助手来询问，尽管有时候回答是错误的，但也能启发一些理解的思路，说出来问题和他人对话，比自己一个人想的效果在某些情况下要好很多。</p><p>对于流媒体和文章类的信息，需要自己理解将这些内容归纳和总结。</p><p>对于Paper和书籍类的信息，则需要用一些处理工具（当然，文章类和媒体类也可以用，主要是帮助自己理解）。</p><p>MarginNote3 十分擅长创建一本书的思维导图，并提供了便捷的跳转功能。可以将整本电子书的内容结构化，在回顾思维导图的时候，可以点击每一块来快速访问原文。这个软件可以处理书籍。</p><p>但是，人们总是喜欢写写画画。在ipad的上，MarginNote对于书写的体验并不是很好。GoodNotes可以说是书写体验极佳的一款笔记软件。可以用它处理Paper，在Paper上勾画做笔记。</p><p>这两款软件的资源来自于icloud，icloud是在Collector阶段获取的。</p><p>icloud与苹果的搜索是联动的，而且搜索速度也很快。如果想看一个文章的笔记还要再打开GoodNotes等，相当麻烦。可以采用的策略就是把做好笔记的Paper覆盖原有的内容。</p><h3 id="Maintainer"><a href="#Maintainer" class="headerlink" title="Maintainer"></a>Maintainer</h3><p>维护器的本质就是存储信息和数据的数据库。这里采用的是Notion作为数据管理中心。原因是它可以在任何平台访问，包括在Web端，没有硬件限制，随时随地取用和检索。</p><p>我在Notion创建KMU和ICU两个page。KMU负责结构化的组织和管理笔记和知识，需要使用者主动的输出和维护。ICU则是快速缓存每天的Idea和获取的原始信息（raw info），需要周期性的被processor处理和固化到KMU才能变成有用的信息。</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>调度器的工作是最重要的。当把信息处理好并固化到你的Maintainer当中，放在那里不动是不管用的。你需要对相关信息即使的更新维护和复习，加深对这些东西的理解，反复提高KMU内容的可理解性和可阅读性。</p><p>我经常遇到的问题是：当我学习某个领域的信息，大脑在这个语境之下，理解知识后，写笔记的过程中就会主动忽略掉某些自认为已经清晰的细节，导致写出来的笔记和内容并不连贯。这就导致，当一段时间没复习时，再回顾这个笔记，有很多地方读起来不通顺，并且很多细节又不理解了，还要花大量时间重新理解和推导。</p><p>解决这个问题的方法有两个：</p><ul><li>定期的复习，始终让大脑熟悉这个领域的语境下</li><li>周期性的维护，提升笔记阅读的流畅性和可理解性</li></ul><p>这就需要一个调度器来管理日常的复习和任务（当然，最最重要的还是个人的执行力）。</p><p>调度器使用的是苹果的calendar，可以实现iphone、watch、mac之间的同步提醒功能。我把它当作个人的日常规划软件，主要是指定计划和提醒。</p><h2 id="Project-Flow"><a href="#Project-Flow" class="headerlink" title="Project Flow"></a>Project Flow</h2><p>Project包括电子设计项目、大型程序项目、难度高的编程任务以及课程Lab等。这类Project的特点是复杂度高，需要很强的分层设计来降低任务的复杂度。如果一头黑的去完成这类任务时，成功率很低，即使成功，做出来的项目的可维护性、可读性和可扩展性也绝对不高。</p><p>因此，在开始任务前，对任务建立一个high-level角度的理解，再通过细粒度的划分层级结构，将抽象思想融合进去，能够全方面提高项目的质量和成功率。</p><p>同时，设置相关的Deadline，不断推进任务也至关重要。</p><h3 id="High-level-Understanding"><a href="#High-level-Understanding" class="headerlink" title="High-level Understanding"></a>High-level Understanding</h3><p>对一个技术或项目的高层理解，建立在直觉上。可以用通俗易懂的语言去描述它是这个阶段的目标。这也是学习的过程，因此可以采用Study Flow的流程，首先扫去知识盲区。</p><p>扫去知识盲区之后，下一步就是通过画草图的形式，将概念和架构可视化，清晰的表述不同组件和模块之间的关系。</p><h3 id="Divide-and-Conquer-amp-amp-Abstract"><a href="#Divide-and-Conquer-amp-amp-Abstract" class="headerlink" title="Divide and Conquer &amp;&amp; Abstract"></a>Divide and Conquer &amp;&amp; Abstract</h3><p>分而治之和抽象是解决复杂任务的关键。在设计系统时，首先仔细思考如果将目标抽象、并划分为不同组件；进一步考虑每个组件之间的关系是什么，为了实现high-level的效果，如何分配每个组件的功能。</p><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><p>这是最后一步，采用各种不同的技术和数据结构、算法，实现每一个功能。</p><p>在project开始时，首先要从coarse-grain和fine-grain的角度理解系统，general overview的直觉要有，技术细节也要有。尝试用抽象的方式，对需要的对象抽象，并探索抽象出的组件之间的关系。</p><p>之后就是项目的实时推进过程，从项目层面进行任务划分，和时间上进行任务划分（因为不可能一天就写完项目）。每天完成分配好的项目后，因为面对的是一个复杂系统，要对当前所完成的功能和在全局视野中的位置做一个标定，意识到自己在哪，该干什么，然后对明日的任务或之后的任务进一步划分。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Study </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMU 15-445 Buffer Pool Manager</title>
      <link href="/2023/04/01/Buffer_Pool_Manager/"/>
      <url>/2023/04/01/Buffer_Pool_Manager/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Buffer Pool Manager Instance这个Task本质而言就是理解清楚Extendible Hash Table和LRU-K Replacer的关系，然后将它们组合起来。实现的难度并不高，只要按照注释内容好好分析，然后按逻辑写下来就可以。重点在于每一个操作的细节问题，细节问题很多，要时刻注意。</p></blockquote><h2 id="Buffer-Pool-Manager-Mechanism"><a href="#Buffer-Pool-Manager-Mechanism" class="headerlink" title="Buffer Pool Manager Mechanism"></a>Buffer Pool Manager Mechanism</h2><p>想要实现Buffer Pool Manager，我们就要在high-level的角度理解一下Buffer Pool Manager在系统中的作用。先看下图：</p><p><img src="bpm1.png" alt=""></p><p>站在System的角度看，System会向Buffer Pool Manager发送一个请求，指定一个page id，Buffer Pool Manager返回这个page在内存中的地址（或者新建一个page）。仅此而已，系统只需要关心要那个page，并等待Buffer Pool Manager返回即可。</p><p>接下来我们去BPM内部看一下。当System想要Fetch一个page时，为了快速在内存中找到指定page id的位置，这里用了Extendible Hash Table。根据之前实现的Hash Table，执行Find操作，将对应的位置，也就是frame id查询出来（<strong>因为Buffer Pool Manager在内存中创建page slot的时候是以数组的形式创建的，因此frame id对应的就是数组的下标索引</strong>）。接着我们可以在内存中找到，并返回page的地址即可。</p><p>如果Fetch操作在哈希表中没找到对应的frame id，说明内存中并不存在这个page。接下来做的操作，就是想从Disk中将对应page的数据copy进来，同时在内存中给它找到一席之地。</p><p>从上图的Buffer Pool中可以看到，内存中灰色的page表示的是当前没有存放page的内存块。因此想从Disk中复制数据进来时，我们就可以先看看Free List中有无空闲的空间。如果有，就采用这个对应的frame id。如果没有，说明内存中所有的page全都放满了，那么就需要从LRU-K Replacer中，选取一个适合驱逐的内存块驱逐它，留出位置给从Disk copy的page使用。</p><h2 id="Buffer-Pool-Manager-Instance-Implementation"><a href="#Buffer-Pool-Manager-Instance-Implementation" class="headerlink" title="Buffer Pool Manager Instance Implementation"></a>Buffer Pool Manager Instance Implementation</h2><p>相关文件夹提供了API及其注释，分别有<code>NewPgImp</code>、<code>FetchPgImp</code>、<code>UnpinPgImp</code>、<code>FlushPgImp</code>、<code>FlushAllPgsImp</code>以及<code>DeletePgImp</code>需要我们实现。相关实现需要注意的地方注释中写的很清晰，当然还有很多细节部分注释中并没有标注出来。比如哈希表的增加和删除的时机、pin count增加的时机等等，这些都是需要自己去debug过程中发现代码漏洞而去补全的。</p><p>这里主要说明一下数据结构部分。<code>pages_</code>是一个page数组的首地址，既然是数组，那说明它们的内存空间是连续的，而且支持随机查找。<code>pages_</code>的索引就是frame id，表明这是buffer pool中第几个slot。<code>disk_manager_</code>我们只需要用到其中的<code>WritePage</code>和<code>ReadPage</code>的API即可。<code>page_table_</code>实现的是page id到frame id的映射关系，使得对指定page id的查找时间复杂度从O(N)降到了O(1)。使用这个数据结构的时候，要注意删除一个page时随即删除<code>page_table_</code>的相关记录，不然之后会导致读到的page的内容是不同page id内容的情况。<code>replacer_</code>的作用是，如果当前buffer pool全部满了，提供一个可驱逐的frame id号，buffer pool manager会根据这个frame id对这块内存进行驱逐，再把想要的page从Disk拷贝到这块内存中。</p><p>关于线程安全，我还是一把大锁锁住所有，尝试过优化，但并没有明显的效果。Leaderboard的结果在2.1s左右。希望各位大佬能对优化方案提供一些建议。</p><p>附一张截图：</p><p><img src="bpm2.png" alt=""></p><h3 id="踩坑记录"><a href="#踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录</h3><ul><li><code>FlushPgImp</code>并不是要将指定page重写回disk并刷新这块内存空间的意思，单纯就是为了将这page写会Disk刷新一下，不改变其在内存中的状态。<code>FlushAllPgsImp</code>同理。</li><li>每次<code>FetchPgImp</code>，就要增加指定page中的pin count。</li><li>Evict和Remove一个page之后，不要忘记<code>ResetMemory</code>。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Database Management System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMU 15-445 LRU-K Replacement Policy</title>
      <link href="/2023/03/26/LRU-K_Replacement_Policy/"/>
      <url>/2023/03/26/LRU-K_Replacement_Policy/</url>
      
        <content type="html"><![CDATA[<blockquote><p>实现LRU-K的时候，先去完成了LeetCode的146题LRU，实现的时候运用了哈希链表结构，题目中要求get和put操作都是O(1)的时间复杂度。一种实现方式就是用STL的list和unordered map，list本质是双向链表，但实现出来最后的结果总是不尽人意。因此将list结构换成自己实现的双向链表，运行起来的速度和内存都优于list的实现。因此在15-445的LRU的实现中，我也采用了自己实现的一个内嵌结构体作为双向链表的基础。总体而言，参考了网上对于LRU-K的讲解之后，对LRU-K的算法操作还是比较清晰的，不像Extendible Hash Table那样一知半解。所以实现起来也很清晰。但由于用的是自己写的双向链表，debug花时间最久的就是内存泄漏问题，因为之前写过的一些项目都没有考虑，因此花了很长时间去定位错误。总体来说是一个教训。</p></blockquote><h2 id="Replacement-Policy"><a href="#Replacement-Policy" class="headerlink" title="Replacement Policy"></a>Replacement Policy</h2><p>缓存驱逐算法的应用场景是，由于内存和硬盘之间读写速度的巨大差异，并且有程序局部性原理的存在，我们想通过<strong>保存从硬盘中读取出的东西在内存中</strong>，这样一种方法来尽可能减少两者之间速度的差异，提高CPU的利用率和处理速度，减少不必要的等待时间。从硬盘中读取出的数据一定是换存在内存中的，而由于内存的大小局限性，我们不可能无限的存储硬盘的page，甚至只能分配内存的一小部分作为缓存空间来使用。</p><p>这样的缓存空间一定是有大小的，有大小就会涉及到缓存存满的问题。如果想要再存放新读入的数据到缓存空间中，必须选择一个内存块将其驱逐出去。把空间给腾出来。选择哪一块驱逐，就是替换算法（replacement policy）所做的事情。一般常见的替换策略有FIFO，LRU以及LFU等等。</p><p>下图展现了硬盘数据和内存之间提取（Fetch）和驱逐（Evict）的关系。</p><p><img src="lruk1.png" alt=""></p><p>上面图片中，Buffer Pool就是缓存数据的池子，最大容量为3个page。Disk上面的Data数不胜数，当需要数据时系统会从Buffer Pool检索，如果检索到了，则直接从内存中提出数据，并且通知<strong>LRU-K Replacement Policy</strong>组件调用了这个page。如果没检索到，就从硬盘中读取一块。如果此时Buffer Pool满了，那就询问<strong>LRU-K Replacement Policy</strong>组件，索要一个可以驱逐的frame id号，系统再根据这个frame id从内存中把对应的page重新写回硬盘（<strong>NOTE：LRU-K不做任何实际的数据操作，仅仅是记录frame的状态，并根据一定的策略将可以驱逐的frame id号提供给系统</strong>）。</p><h2 id="LRU-and-LRU-K"><a href="#LRU-and-LRU-K" class="headerlink" title="LRU and LRU-K"></a>LRU and LRU-K</h2><p>建议还是去做一下力扣146题，通过这道题可以了解LRU的算法流程。LRU其实很简单，用语言表述一句话就是：选择最长时间不访问的page驱逐。话是这么说，实现上还是需要一些技巧的。题目中需要实现两个方法，一个是get一个是put。put是给定一个key，value，将其存入链表中。get操作是给定key，返回一个key对应的value，并删除对应的key/value pair。题目要求两个操作的时间复杂度为O(1)。</p><p>链表的插入和删除操作的复杂度为O(1)，但是查找的时间复杂度为O(N)。这就没办法满足get操作的要求。我第一次实现的时候直接用了C++的list容器，结果最后超时了。如果查找满足时间复杂度为O(1)，就需要用哈希数据结构。但哈希表是无序结构，LRU需要有序结构。结合两者的优点，就是哈希链表。查找时索引哈希表，得到对应链表的地址，插入和删除时直接用双向链表的删除即可。</p><p>用例子来理解一下LRU的算法。假设LRU最大存储量为3，接下来对算法进行put(1, 1), put(2, 2), put(3, 3), get(2, 2), put(1, 2)的操作。看下图的操作顺序（<strong>我实现的方式是，链表头是要驱逐的元素，链表尾部是最新使用过的元素</strong>）。</p><p><img src="lruk2.png" alt=""></p><p>当然这只是双向链表的视角，别忘了，为了实现O(1)的get操作，我们还有一个哈希结构。下面是一个哈希链表结构的示意图。</p><p><img src="lruk3.png" alt=""></p><p>新增的头节点L和尾节点R可以用来直接对头部和尾部进行操作，头部要移除，尾部要插入，就不必去寻找头尾节点了。这两个头尾节点在之后的LRU-K算法实现中会扩展成头部、中间和尾部节点，关于这部分之后在叙述我的想法。</p><p>Leetcode的代码实现如下：</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;unordered_map></span></span><span class="token keyword">class</span> <span class="token class-name">LRUCache</span> <span class="token punctuation">&#123;</span><span class="token keyword">private</span><span class="token operator">:</span>    <span class="token keyword">struct</span> <span class="token class-name">Node</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">int</span> key_<span class="token punctuation">;</span>        <span class="token keyword">int</span> val_<span class="token punctuation">;</span>        Node<span class="token operator">*</span> left <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>        Node<span class="token operator">*</span> right <span class="token operator">=</span> <span class="token keyword">nullptr</span><span class="token punctuation">;</span>        <span class="token function">Node</span><span class="token punctuation">(</span><span class="token keyword">int</span> k<span class="token punctuation">,</span> <span class="token keyword">int</span> v<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token function">key_</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">val_</span><span class="token punctuation">(</span>v<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">left</span><span class="token punctuation">(</span><span class="token keyword">nullptr</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">right</span><span class="token punctuation">(</span><span class="token keyword">nullptr</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> size<span class="token punctuation">;</span>    <span class="token keyword">int</span> capacity_<span class="token punctuation">;</span>    std<span class="token double-colon punctuation">::</span>unordered_map<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> Node<span class="token operator">*</span><span class="token operator">></span> cache_map_<span class="token punctuation">;</span>    Node <span class="token operator">*</span>R<span class="token punctuation">;</span>    Node <span class="token operator">*</span>L<span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    <span class="token function">LRUCache</span><span class="token punctuation">(</span><span class="token keyword">int</span> capacity<span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token function">capacity_</span><span class="token punctuation">(</span>capacity<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        R <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Node</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        L <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Node</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        R<span class="token operator">-></span>right <span class="token operator">=</span> L<span class="token punctuation">;</span>        R<span class="token operator">-></span>left <span class="token operator">=</span> L<span class="token punctuation">;</span>        L<span class="token operator">-></span>right <span class="token operator">=</span> R<span class="token punctuation">;</span>        L<span class="token operator">-></span>left <span class="token operator">=</span> R<span class="token punctuation">;</span>        size <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">void</span> <span class="token function">insertNode</span><span class="token punctuation">(</span>Node <span class="token operator">*</span>node<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token comment">// insert to back of list</span>        node<span class="token operator">-></span>left <span class="token operator">=</span> R<span class="token operator">-></span>left<span class="token punctuation">;</span>        node<span class="token operator">-></span>right <span class="token operator">=</span> R<span class="token punctuation">;</span>        R<span class="token operator">-></span>left<span class="token operator">-></span>right <span class="token operator">=</span> node<span class="token punctuation">;</span>        R<span class="token operator">-></span>left <span class="token operator">=</span> node<span class="token punctuation">;</span>        size<span class="token operator">++</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">void</span> <span class="token function">moveNodeToBack</span><span class="token punctuation">(</span>Node <span class="token operator">*</span>node<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token function">eraseNode</span><span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">insertNode</span><span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">void</span> <span class="token function">eraseNode</span><span class="token punctuation">(</span>Node <span class="token operator">*</span>node<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        node<span class="token operator">-></span>left<span class="token operator">-></span>right <span class="token operator">=</span> node<span class="token operator">-></span>right<span class="token punctuation">;</span>        node<span class="token operator">-></span>right<span class="token operator">-></span>left <span class="token operator">=</span> node<span class="token operator">-></span>left<span class="token punctuation">;</span>        size<span class="token operator">--</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>        <span class="token keyword">int</span> <span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">auto</span> it <span class="token operator">=</span> cache_map_<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>it <span class="token operator">!=</span> cache_map_<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            <span class="token function">moveNodeToBack</span><span class="token punctuation">(</span>it<span class="token operator">-></span>second<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> it<span class="token operator">-></span>second<span class="token operator">-></span>val_<span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>        <span class="token keyword">void</span> <span class="token function">put</span><span class="token punctuation">(</span><span class="token keyword">int</span> key<span class="token punctuation">,</span> <span class="token keyword">int</span> value<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">auto</span> it <span class="token operator">=</span> cache_map_<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>it <span class="token operator">!=</span> cache_map_<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            it<span class="token operator">-></span>second<span class="token operator">-></span>val_ <span class="token operator">=</span> value<span class="token punctuation">;</span>            <span class="token function">moveNodeToBack</span><span class="token punctuation">(</span>it<span class="token operator">-></span>second<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>size <span class="token operator">==</span> capacity_<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>            cache_map_<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>L<span class="token operator">-></span>right<span class="token operator">-></span>key_<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">eraseNode</span><span class="token punctuation">(</span>L<span class="token operator">-></span>right<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>        <span class="token keyword">auto</span> node <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token function">Node</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">insertNode</span><span class="token punctuation">(</span>node<span class="token punctuation">)</span><span class="token punctuation">;</span>        cache_map_<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>LRU-K算法是LRU算法的改进版。LRU算法存在的问题是，当存在大量的一次性操作时，会把历史的缓存冲刷掉，而新进入buffer pool的page有可能之后不会再访问了，被冲刷掉的page是之前保留下来的比较“有用”的page，这就是<strong>缓存污染</strong>问题。</p><p>LRU-K的思路是，永远最先驱逐访问次数小于K次的page。网上的很多讲解是直接维护两个链表，一个叫做history list，另一个叫buffer list。新加入的page总会先进入history list，当访问次数等于指定的次数K次时，就会从history list删除，并移动到buffer list的尾部（<strong>这里还是假设尾部的page是最新使用的，头部page是最近最久未使用的</strong>）。</p><p>通过例子来理解一下这个LRU-K算法，首先插入key=1，2，3，它们的value分别是1，1，1。原因是这里的value我用它来记录K的次数，也就是访问的次数。现在假设整个history list和buffer list最多存储三个page，就是buffer pool的大小，且K=2。首先我们访问key=1的page，那么对应的node的value就会变为2，一旦等于了K的值，说明这个page是可能被经常访问的，就把它移入buffer list。</p><p><img src="lruk4.png" alt=""></p><p>接着我们再访问key=2的page。</p><p><img src="lruk5.png" alt=""></p><p>Buffer list服从LRU算法，History List可以服从任意替换算法，在实验手册中，要求驱逐最早进入history list的page，采用的是FIFO策略（<strong>刚开始我实现的history list是LRU策略，结果会导致Evict Test无法通过，一定要注意history和buffer的策略不一样</strong>）。</p><p>接着我们尝试插入key=4的page，结果发现buffer pool满了（总共的空间为3，history占1，buffer占2），那么就需要对某一个page进行缓存驱逐，根据原则：<strong>永远最先驱逐访问次数小于K的page</strong>。所以先驱逐掉3，再加4到history list中。</p><p><img src="lruk6.png" alt=""></p><p>History list采用FIFO，由于History list只剩下3了，那么只能驱逐3。如果继续访问4，那么4会被移入Buffer list中，此时buffer pool也已经满了。如果想再插入一个新的page，需要缓存驱逐，这时就要从buffer list里面根据LRU算法进行驱逐了，具体的例子可以自行画一下。</p><p>以上就是LRU和LRU-K算法的解释。</p><h2 id="LRU-K-Implementation"><a href="#LRU-K-Implementation" class="headerlink" title="LRU-K Implementation"></a>LRU-K Implementation</h2><p>实现15-445 LRU-K任务的时候，我采用的还是使用自己定义的结构体Node和STL的unordered_map结构，实现哈希链表。链表不使用STL的list的一个原因是Leetcode跑下来的结果优于使用STL的list，性能方面会更好；另一个原因就是结构体定义数据和操作的自由度高，可以根据自己的想法来实现。缺点就是，<strong>要注意内存泄漏问题（由于之前经验很少，此处debug时间花的很多）</strong>。</p><p>实现思路总体继承Leetcode的解法，定义一个有key，value，左右指针的节点，同时为了区分每一个节点是否evictable，加如了一个bool变量。其中，key存储对应的frame_id，value代表被访问的次数，evictable表示这个节点是否可以被驱逐。</p><p>设计双链表的时候，除去左节点L和右节点R，我还加入了一个中间节点M，作为history list和buffer list的分割节点。两种list连接在一条双向链表上，再用unordered map索引。</p><p>具体的效果如下图：</p><p><img src="lruk7.png" alt=""></p><p>然后对history list和buffer list分别维护一个计数器，计算当前包含的节点数量，可用来判断是否需要驱逐缓存（注意需要迭代判断，并不能直接取L节点或M节点的下一个，因为下一个节点很有可能是non-evictable的）。</p><p>线程安全方面是直接一把大锁锁住所有操作。并没有细致的对每一个结构进行优化。</p><h3 id="踩坑记录"><a href="#踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录</h3><ul><li><p>最主要的问题就是内存泄漏问题，真的是种种内存泄漏。最大的原因就是，程序结束之后，有一些内存中的节点，没有被人为的Remove或者Evict，导致结束程序后将这些节点遗留下来，造成的内存泄漏。解决方案就是在Replacer的析构函数里实现一个强制去除当前链表所有节点的程序（包括non-evictable，因为之前实现的是直接循环Evict，再删除L，M和R，但总还是有内存泄漏问题，原因在于Evict仅仅驱逐evictable数据，析构函数调用它会删不干净）。还有的内存泄漏问题就是use after free问题。这个问题值得是在释放内存空间后还尝试使用这个内存空间。经典出现的地方在于，删除节点的时候要伴随哈希表对应数据的删除。需要注意的是哈希表的<code>erase</code>方法：如果用key删除，且value存储的是指针，那么仅仅会删掉哈希表中的数据，指针所指向的内存是不会被删除的；如果用迭代器删除，我们首先应当删除迭代器的second所指向的内存空间，然后再删除迭代器的first对应的key。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token comment">// hash_map_&lt;int, Node*></span><span class="token keyword">auto</span> it <span class="token operator">=</span> hash_map_<span class="token punctuation">.</span><span class="token function">find</span><span class="token punctuation">(</span>frame_id<span class="token punctuation">)</span>；hash_map_<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>it<span class="token operator">-></span>first<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">EraseNode</span><span class="token punctuation">(</span>it<span class="token operator">-></span>second<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 报错use after free，因为已经删除了对应的数据，迭代器不可用，it无法索引到</span>Node <span class="token operator">*</span>p <span class="token operator">=</span> L<span class="token operator">-></span>right<span class="token punctuation">;</span> <span class="token comment">// 取出头节点</span>hash_map_<span class="token punctuation">.</span><span class="token function">erase</span><span class="token punctuation">(</span>p<span class="token operator">-></span>key<span class="token punctuation">)</span>；<span class="token function">EraseNode</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span>； <span class="token comment">// 成功，因为hash map只删除了表中存储的数据，原Node内存还存在</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>History list用的是FIFO，Buffer list采用LRU。我开始都用的LRU，导致EvictTest报错。</p></li><li>注意要实现自己的双向链表的删除，插入和移动的相关函数。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Database Management System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMU 15-445 Extendible Hash Table</title>
      <link href="/2023/03/22/Extendible_Hash_Table/"/>
      <url>/2023/03/22/Extendible_Hash_Table/</url>
      
        <content type="html"><![CDATA[<blockquote><p>最近在学习CMU的15-445 DB课程，在做Project1的Extendible Hash Table的时候，由于是先看了课程，过了一个多星期才做的Lab，对extendible hash table只能说是知道大体的意思，并没有透彻的了解它，尤其是bucket指针和数据重分配这一部分，涉及到比较tricky的位运算，在一知半解的情况下实现它，完全没办法找到对应的bug，ConcurrentInsertFindTest和GetNumBucketsTest总是fail。又去参考了很多对可扩展哈希的文章，才发现自己一些细节是错误的。本篇文章尝试以我的理解说清楚extendible hash table，并作为我的菜坑记录。</p></blockquote><h2 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h2><p>这一部分的任务就是搭建一个通用的存储unique KV对的哈希表。我们需要实现哈希表的插入、删除以及查找操作。实验手册中并没有要求我们实现shrink部分，所以只需要关注如何扩展哈希表即可。代码在<code>scr/include/container/hash/extendible_hash_table.h</code>以及 <code>extendible_hash_table.cpp</code>下，实现之前建议先阅读这两个文件的代码和注释，明确我们的目标。</p><h2 id="Overview-of-Extendible-Hash-Table"><a href="#Overview-of-Extendible-Hash-Table" class="headerlink" title="Overview of Extendible Hash Table"></a>Overview of Extendible Hash Table</h2><p>在理解可扩展哈希表之前，我们需要了解几个概念。</p><ul><li><strong>Directory</strong>：是存放bucket指针的容器，可动态生长（以原大小的倍数作为增长率），容器的每个元素可用哈希值来索引。</li><li><strong>Bucket</strong>：桶。存放Key/value pair的桶，数据结构层面是一个线性表。</li></ul><p>下面是一个简单的可扩展哈希表的示意图，具体不用关心它是怎么来的，先对它建立一个直观的印象即可。</p><p><img src="eht1.png" alt=""></p><p>上图又出现两个概念：</p><ul><li><strong>Global Depth</strong>：假设global depth为n，那么当前的directory必定有$2^n$个entry。例如，当前$n=2$，那么就有4个entry，$n=3$就有8个entry。同时，给定一个key，需要用global depth取出这个key的低n位的二进制值。例如，一个key的二进制是10111，如果global depth是3，通过<code>IndexOf(key)</code>函数，得到返回值的二进制值是111，即为7。这个值用来索引directory[111]位置的bucket。</li><li><strong>Local Depth</strong>：local depth指的是（假设local depth为n），在当前的bucket之下，每个元素的key的低n位都是相同的。</li></ul><p>两者之间有什么关系呢？</p><ul><li>对于一个bucket来说，如果当前的global depth等于local depth，那说明这个bucket只有一个指针指向它。</li><li>如果当前的global depth大于local depth，必定不止一个指针指向它。</li><li>计算当前bucket有几个指针指向它的公示是$2^{globalDepth-localDepth}$。</li></ul><p>Global depth和local depth的概念就是这些，然而在实现算法的过程中还有对这些概念的应用，我们暂且先忽略，之后的部分会一一阐述。</p><h2 id="Implementation-Scheme"><a href="#Implementation-Scheme" class="headerlink" title="Implementation Scheme"></a>Implementation Scheme</h2><p>对于Bucket的Insert，Remove以及Find操作，熟悉一下C++的list容器相关操作就可以实现。不过有一个地方需要注意的是，实现bucket的Insert方法时，注释里说的是先检查key是否存在，如果存在就要更新value。这里如果先判断bucket是否满了，就会出现bug。因为如果一个bucket满了，但刚你要插入的key在这个bucket的中，先判断是否满的话就会直接返回，不会更新对应key的value，就会造成之后find的错误。</p><p>实现了Bucket的三个操作之后，就可以实现ExtendibleHashTable的三大操作了。为了确保线程安全，每一个操作应当加锁来保证。</p><p>这里阐述一下Insert的算法流程，然后结合一个具体的例子，分析算法可能遇到的情况。</p><ol><li>尝试插入Key，若插入成功，返回即可，若不成功，执行步骤2。</li><li>判断当前<code>IndexOf(key)</code>指向的bucket下，该bucket是否满了。如果满了，执行步骤3。否则执行步骤7。</li><li>如果当前global depth等于local depth，说明bucket已满，需要增长direcotry的大小。增加directory的global depth，并将新增加的entry链接到对应的bucket。否则，继续执行步骤4。</li><li>记录当前的local mask，创建bucket1和bucket2，增加两个bucket的local depth，增加num bucket的数量。取出之前满了的bucket中的元素，按照local mask的标准将每个元素重新分配到bucket1和bucket2中。执行步骤5。</li><li>对每个链接到产生overflow的bucket的direcotry entry，按照local mask的标准，重新分配指针指向。执行步骤6。</li><li>重新计算<code>IndexOf(key)</code>，执行步骤2。</li><li>插入指定的key/value pair。</li></ol><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><p>这个例子来自于官方的Homework #2 - Question 3。假定每一个bucket的容量大小为2，且哈希函数用最低的g个二进制位，g指global depth。</p><p>按顺序插入15，14，23，11，9。这几个数对应的二进制分别是，1111，1110，10111，1011，1001。</p><p><strong>STEP 1</strong>：首先插入15和14，第一步没什么问题。</p><p><img src="eht2.png" alt=""></p><p><strong>STEP 2</strong>：接着插入23，23的二进制是10111，当前的global depth是0，计算得到的<code>IndexOf(key)</code>是0，说明23要插入到directory的第0个entry中，但是这个entry所指向的bucket满了。我们执行步骤3（<strong><em>重复一下步骤3：如果当前global depth等于local depth，说明bucket已满，需要增长direcotry的大小。增加directory的global depth，并将新增加的entry链接到对应的bucket。否则，继续执行步骤4</em></strong>）。</p><p><img src="eht3.png" alt=""></p><p>这一步有一个很重要的点，新增长的entry怎么分配到对应的bucket？如果和上图的情况一样，从1增长到2，只需要把多出来的一个拉到唯一的bucket上就可以了，但如果从2到4，从4到8呢？多出来的若干个如何处理？其实只需要将多出来的一部分指针完全复制之前的一份就可以了。这样做法我觉得是可扩展哈希的比较重要的细节，由于可扩展哈希扩展direcotry时是按照当前大小的两倍进行扩展，新增长出来的部分作为之前directory的对等实体，每一个新的entry都对应了之前对应的entry，指向相同的bucket。唯一的不同就是之前的direcotry的索引最高位是0，扩展出来的最高位是1。</p><p><img src="eht4.png" alt=""></p><p><strong>STEP 3</strong>：执行步骤4（<strong><em>记录当前的local mask，创建bucket1和bucket2，增加两个bucket的local depth，增加num bucket的数量。取出之前满了的bucket中的元素，按照local mask的标准将每个元素重新分配到bucket1和bucket2中。执行步骤5</em></strong>）。</p><p>当前local mask的计算方法是<code>1 &lt;&lt; local_depth</code>，其中的local depth是指<strong>STEP 2</strong>图片中，扩展之前的local depth，即为0。</p><p>为什么呢？因为在扩展之前，产生overflow的bucket中的数据，低local depth个的二进制位完全相同，在<strong>STEP 2</strong>的图片例子中，1111和1110没有相同的低位二进制位，因此local depth是0。现在要插入23（0b10111），由于bucket已经满了，所以我们需要分裂bucket、重分配KV pair、重分配entry的指向。分裂了bucket，就产生两个bucket。</p><p>怎么放KV pair呢？我们总不能乱放吧？我们肯定要有规律的去分配。1111和1110，由于之前local depth为0，表明不需要参考任何二进制位，因此可以放到一个bucket里。当插入10111时，一个bucket放不下了，就需要两个bucket，为了可以高效的查询，当然是<strong>归类分配</strong>才行。按什么归类？当我们给事物归类的时候，我们会按属性归类，玩具为一类，家具为一类。二进制怎么归类呢？我们可以从最低位二进制位开始对比，之前不需要对比，现在我们至少需要对比一个二进制位，才能将3个二进制数分为两类（2个+1个，如果对比一个二进制位还不行，就继续增加local depth）。local mask的意思就是，之前local depth为0，不需要对比，但我现在要对比第一位，那么我就可以使用<code>1 &lt;&lt; local_depth</code>，1左移0位还是1，就是对比第一位二进制位。通过对比，1111和1110就不再是一类了，可以分别放入不同的bucket。</p><p><img src="eht5.png" alt=""></p><p><strong>STEP 4</strong>：执行步骤5（<strong><em>对每个链接到产生overflow的bucket的direcotry entry，按照local mask的标准，重新分配指针指向。执行步骤6</em></strong>）。</p><p><img src="eht6.png" alt=""></p><p><strong>STEP 5</strong>：执行步骤6，重新计算<code>IndexOf(key)</code>，由于改变了global depth，新计算的IndexOf(key)是1，最后执行步骤2，判断1指向的bucket没满，执行步骤7，插入23。</p><p><img src="eht7.png" alt=""></p><p><strong>STEP 6</strong>：接下来我们插入11（0b1011）。<strong>NOTE：这个例子在实现的过程中容易忽略掉</strong>。首先计算<code>IndexOf(key)</code>，得到结果为1，我们就要插入红色的bucket。但红色bucket满了，同时，global depth等于local depth，因此需要扩展directory，执行步骤3。</p><p><img src="eht8.png" alt=""></p><p>之前的local depth我们比较最低位的二进制位，将1111和10111放入了一个bucket，由于该bucket产生了overflow，又分裂为两个bucket，我们就需要对这个产生overflow的bucket中的元素重新归类。正常情况下，产生overflow的bucket的中的元素可以被平均的分布到两个bucket中，但这个例子中，我们对比两个数的第二位，发现1111和10111最低的第二位仍然是1，那么还是将两者化为一类。并更新与overflow的bucket相关的directory entry的指向。</p><p><img src="eht9.png" alt=""></p><p>复杂的问题又来了，之前01和11的entry都指向一个bucket，在分裂的时候，我们怎么去redirect呢？答案是利用local depth和local mask。<strong>分裂之前的local depth为1（0b01），意味着指向这个bucket的最低一位二进制位都相同</strong>。01和11两个数的最低一位二进制位都是1。我们要分裂bucket，一定是bucket已经满了，也说明当前比较二进制位最低一位在将来不适用了，因为连上要插入的数，三个数的最低一位二进制位都是1，因此我们才需要local mask，将1（0b01）左移local depth位，变为2（0b10），意味着我们需要考量第二位二进制位才能区分三个数（这里的entry、global depth还有local depth之间的关系比较难理解）。<strong>想要redirect指向同一个bucket的所有entry，我们必须遍历一次directory</strong>。但并不是暴力遍历，通过观察可以发现，01和11刚好相差一个local mask，而且01作为遍历的开始，可以通过<code>hash(key) &amp; (local_mask - 1)</code>计算得到。</p><p>为什么是<code>hash(key) &amp; (local_mask - 1)</code>呢？首先<code>hash(key)</code>可以理解为得到了key的二进制数，local mask是由local depth得到的，local depth表明的是存放在当前bucket中所有key的低位二进制位相等的个数。local mask是下一个需要检查的二进制位的位置。同时我们也知道，既然key能插入这个bucket，<strong>那么说明key和存放于这个bucket中的keys是有共同性的</strong>，这个共同性就是：<strong>低local depth位二进制数完全相同</strong>。local_mask - 1和key的二进制&amp;的结果就是在directory中，最开始的那个entry，因为这个entry的值完全等于<code>hash(key) &amp; (local_mask - 1)</code>。其余所有指向这个bucket的entry，唯一与这个最开始的不同就是：local depth + 1位是0和1的区别。就是相差local mask。</p><p>啊，好复杂，感觉没有说清楚，后续可能更新一下，如果没懂可以私信我或者评论区讨论一下。</p><p>更新<code>IndexOf(key)</code>，由于global index变为2，这时的index就是0b11，即第四个directory。进入步骤2。</p><p><strong>STEP 7</strong>：判断是否能插入蓝色bucket，很明显，bucket又满了，且global depth等于local depth。进行扩展哈希表和分裂bucket。然后分配每一个KV pair。</p><p><img src="eht10.png" alt=""></p><p>最后更新<code>IndexOf(key)</code>，结果是0b011，插入绿色的bucket。</p><p><img src="eht11.png" alt=""></p><p>之后的继续添加和扩展大同小异，重点还是理解entry index、global depth和local depth的深层含义，还有相关位运算的思想。</p><h2 id="踩坑记录"><a href="#踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录</h2><ul><li>第一次实现的时候并没有考虑扩展后的指针指向问题，导致程序运行时访问到了nullptr的地址，报错。实际上directory的扩展本质上就是将原来的direcotry完完整整拷贝一份，不同的只是index不同。</li><li>Grade scope做测试的时候，无论如何怎么调试都过不了ConcurrentInsertFindTest和GetNumBucketsTest，尝试着根据在线测试的输出在本地写了若干个对应的测试样例。还是没办法通过。最后阅读别人的文章才发现代码中分配元素的条件和重分配entry指针指向的条件有错误，根本原因还是没理解透彻extendible hash table中的index、global depth和local depth的内涵。以后一定要理解全部的算法内容再考虑代码实现，尤其是细节部分，de这样的bug简直是痛苦。</li><li>在算法的概述中，有涉及到循环插入的过程。在上面的例子中就是插入1011时的情况。判断一个bucket满了，分裂bucket后，将产生overflow的bucket中的元素根据local depth重新分配，结果全部都分配到一个bucket中。这时候如果还是尝试插入1011，是失败的。因此需要通过while迭代，也就是test case中的multi split test。第一次实现的时候并没有考虑到这个问题。</li></ul><p>遵守课程的条例，不公开源码，但我把自己写的相关测试样例放在下面，写的比较粗糙，因为是debug太痛苦时写的。</p><pre class="line-numbers language-cpp" data-language="cpp"><code class="language-cpp"><span class="token function">TEST</span><span class="token punctuation">(</span>ExtendibleHashTableTest<span class="token punctuation">,</span> InsertMultipleSplitTest<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">auto</span> table <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">make_unique</span><span class="token generic class-name"><span class="token operator">&lt;</span>ExtendibleHashTable<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>string<span class="token operator">>></span></span></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token string">"d"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token string">"e"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetNumBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetLocalDepth</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetLocalDepth</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetLocalDepth</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetLocalDepth</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span class="token function">TEST</span><span class="token punctuation">(</span>ExtendibleHashTableTest<span class="token punctuation">,</span> ConcurrentInsertFindTest<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">const</span> <span class="token keyword">int</span> num_runs <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">;</span>  <span class="token keyword">const</span> <span class="token keyword">int</span> num_threads <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>  <span class="token comment">// Run concurrent test multiple times to guarantee correctness.</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> run <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> run <span class="token operator">&lt;</span> num_runs<span class="token punctuation">;</span> run<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">auto</span> table <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">make_unique</span><span class="token generic class-name"><span class="token operator">&lt;</span>ExtendibleHashTable<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">>></span></span></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>thread<span class="token operator">></span> threads<span class="token punctuation">;</span>    threads<span class="token punctuation">.</span><span class="token function">reserve</span><span class="token punctuation">(</span>num_threads<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> tid <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> tid <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> tid<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threads<span class="token punctuation">.</span><span class="token function">emplace_back</span><span class="token punctuation">(</span><span class="token punctuation">[</span>tid<span class="token punctuation">,</span> <span class="token operator">&amp;</span>table<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">int</span> val<span class="token punctuation">;</span>        table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span>tid<span class="token punctuation">,</span> tid<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">EXPECT_TRUE</span><span class="token punctuation">(</span>table<span class="token operator">-></span><span class="token function">Find</span><span class="token punctuation">(</span>tid<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threads<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span>table<span class="token operator">-></span><span class="token function">GetGlobalDepth</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      <span class="token keyword">int</span> val<span class="token punctuation">;</span>      <span class="token function">EXPECT_TRUE</span><span class="token punctuation">(</span>table<span class="token operator">-></span><span class="token function">Find</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token function">TEST</span><span class="token punctuation">(</span>ExtendibleHashTableTest<span class="token punctuation">,</span> ConcurrentInsertFind2Test<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">const</span> <span class="token keyword">int</span> num_runs <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">;</span>  <span class="token keyword">const</span> <span class="token keyword">int</span> num_threads <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">;</span>  <span class="token comment">// Run concurrent test multiple times to guarantee correctness.</span>  <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> run <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> run <span class="token operator">&lt;</span> num_runs<span class="token punctuation">;</span> run<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>    <span class="token keyword">auto</span> table <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">make_unique</span><span class="token generic class-name"><span class="token operator">&lt;</span>ExtendibleHashTable<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token keyword">int</span><span class="token operator">>></span></span></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>thread<span class="token operator">></span> threadsInsert<span class="token punctuation">;</span>    std<span class="token double-colon punctuation">::</span>vector<span class="token operator">&lt;</span>std<span class="token double-colon punctuation">::</span>thread<span class="token operator">></span> threadsFind<span class="token punctuation">;</span>    threadsInsert<span class="token punctuation">.</span><span class="token function">reserve</span><span class="token punctuation">(</span>num_threads<span class="token punctuation">)</span><span class="token punctuation">;</span>    threadsFind<span class="token punctuation">.</span><span class="token function">reserve</span><span class="token punctuation">(</span>num_threads<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> tid <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> tid <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> tid<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threadsInsert<span class="token punctuation">.</span><span class="token function">emplace_back</span><span class="token punctuation">(</span><span class="token punctuation">[</span>tid<span class="token punctuation">,</span> <span class="token operator">&amp;</span>table<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> tid <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token punctuation">(</span>tid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>          table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threadsInsert<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> tid <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> tid <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> tid<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threadsFind<span class="token punctuation">.</span><span class="token function">emplace_back</span><span class="token punctuation">(</span><span class="token punctuation">[</span>tid<span class="token punctuation">,</span> <span class="token operator">&amp;</span>table<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> tid <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token punctuation">(</span>tid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>          <span class="token keyword">int</span> val<span class="token punctuation">;</span>          <span class="token function">EXPECT_TRUE</span><span class="token punctuation">(</span>table<span class="token operator">-></span><span class="token function">Find</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">&#125;</span>      <span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> num_threads<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>      threadsFind<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">join</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">&#125;</span>  <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span><span class="token function">TEST</span><span class="token punctuation">(</span>ExtendibleHashTableTest<span class="token punctuation">,</span> GetNumBucketsTest<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>  <span class="token keyword">auto</span> table <span class="token operator">=</span> std<span class="token double-colon punctuation">::</span><span class="token generic-function"><span class="token function">make_unique</span><span class="token generic class-name"><span class="token operator">&lt;</span>ExtendibleHashTable<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token punctuation">,</span> std<span class="token double-colon punctuation">::</span>string<span class="token operator">>></span></span></span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token string">"b"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token string">"c"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetNumBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token string">"d"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">31</span><span class="token punctuation">,</span> <span class="token string">"e"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token string">"f"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">51</span><span class="token punctuation">,</span> <span class="token string">"g"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetNumBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token string">"h"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token string">"i"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token string">"j"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetNumBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token string">"k"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  table<span class="token operator">-></span><span class="token function">Insert</span><span class="token punctuation">(</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token string">"l"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token function">EXPECT_EQ</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> table<span class="token operator">-></span><span class="token function">GetNumBuckets</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Database Management System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Monodepth2 Paper Note</title>
      <link href="/2022/12/23/Monodepth2/"/>
      <url>/2022/12/23/Monodepth2/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong>Abstract</strong>: Per-pixel ground truth depth data is challenging to acquire at scale. To overcome this limitation, self-supervised learning has emerged as a promising alternative for training models to perform monocular depth estimation. In this paper, we propose a set of improvements, which together result in both quantitatively and qualitatively improved depth maps compared to competing self-supervised methods.</p><p>Research on self-supervised monocular training usually explores increasingly complex architectures, loss functions, and image formation models, all of which have recently helped to close the gap with fully-supervised methods. We show that a surprisingly simple model, and associated design choices, lead to superior predictions. In particular, we propose (i) a minimum reproduction loss, designed to robustly handle occlusions, (ii) a full-resolution multi-scale sampling method that reduces visual artifacts, and (iii) an auto-masking loss to ignore training pixels that violate camera motion assumptions. We demonstrate the effectiveness of each component in isolation, and show high quality, state-of-the-art results on the KITTI benchmark.</p></blockquote><h2 id="1-先验知识"><a href="#1-先验知识" class="headerlink" title="1. 先验知识"></a>1. 先验知识</h2><p>对于自监督或者说无监督学习的单目图像深度估计任务而言，存在两种现有的训练方案。</p><blockquote><ol><li><strong>stereo pairs</strong> 即立体图像对，包含一张左边照相机的图片和一张右边照相机的图片。</li><li><strong>monocular video</strong> 即单目的视频流数据。</li></ol></blockquote><p>对于<strong>monocular video</strong>来说，为了估计图像的深度，由于缺乏相机运动的先验知识，所以模型同样需要估计相机的姿态变化。这通常会额外训练一个叫作 <strong>pose estimation network</strong>_ 的网络，即姿态估计网络。网络的输入是一系列的图像帧，网络的输出是对应的相机变换方式。</p><p><strong>什么是 ill-posed 问题？</strong>不适定问题（ill-posed problem）和适定问题（well-posed problem）是数学领域对问题进行定义的术语。不满足以下三点的任意一点，都是ill-posed问题：</p><blockquote><ol><li>A solution exists. 有解</li><li>The solution is unique. 解唯一</li><li>The solution’s behavior changes continuously with the initial conditions. 解稳定</li></ol></blockquote><p><strong>为什么深度估计是ill-posed问题？</strong> 因为深度估计对于每一张图片会有多个解，且不稳定。</p><p><strong>Occluded pixels</strong>：遮盖的像素点。在某些序列图下，会出现在一张图没有被遮挡，而在另一张图被遮挡的像素点。</p><p><strong>Out of view pixels</strong>：出界的像素点。由于相机的运动，导致某些像素点不在另一张图像上。</p><h2 id="2-本文的主要贡献"><a href="#2-本文的主要贡献" class="headerlink" title="2. 本文的主要贡献"></a>2. 本文的主要贡献</h2><blockquote><ol><li>当使用单目监督时，会产生像素遮盖的现象。为解决这一问题，提出了<strong>外观匹配损失函数</strong>。</li><li>提出了<strong>自动掩码</strong>的方法，可以忽略那些和相机运动无关的像素点。</li><li>提出了<strong>多尺度的外观匹配损失函数</strong>，可以降低深度的暇疵。</li></ol></blockquote><h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h2><h3 id="3-1-自监督学习"><a href="#3-1-自监督学习" class="headerlink" title="3.1 自监督学习"></a>3.1 自监督学习</h3><p>自监督深度估计将学习问题作为一种视图合成问题，即通过一个其他视角的图片来预测目标图片的样子。使用一个中间变量——视差或深度，来限制网络在图像合成任务的学习过程，最后我们就可以提取出这个中间变量，转化成图像的深度图片。这是一个ill-posed的问题，因为如果确定了相机的相对姿态，会有很多图片（图片中的每个像素的深度都不一致）都可以合成出对应视角下的目标图片。经典的双目甚至多目方法通过强化深度图片的平滑度以及计算图片的一致性解决了这个问题。</p><p>该工作仍继续沿用之前的思想，将任务作为视图合成问题，通过目标图像和重建得到的目标图像之间的误差作为学习的指导。</p><p>首先，可以将源图像$I<em>{t’}$与目标图像$I</em>{t}$之间相机的相对姿态表示为$T_{t \rightarrow {t^{‘} } }$。通过预测目标图像的深度图$D_t$，最小化目标图像以及不同的源图像重建出的目标图像之间的误差，实现深度的预测。数学描述为</p><script type="math/tex; mode=display">L_p = \sum_{t'}reconError(I_t, I_{ {t^{'} } \rightarrow t}) \tag 1</script><script type="math/tex; mode=display">I_{ {t^{'} } \rightarrow t} = I_{t^{'} } ( proj(D_t, T_{t \rightarrow {t^{'} } }, K) )\tag 2</script><p>这里的$proj(D<em>t, T</em>{t \rightarrow {t^{‘}}}, K)$可以进一步拆解为如下公式</p><script type="math/tex; mode=display">D_t = DispToDepth(disparity)</script><script type="math/tex; mode=display">CamPoints = BackprojectDepth(D_t, K^{-1})</script><script type="math/tex; mode=display">2Dcoord = Project3D(CamPoints, K, T_{t \rightarrow {t^{'} } })</script><script type="math/tex; mode=display">I_{ {t^{'} } \rightarrow t} = I_{t^{'} } ( 2Dcoord ) \tag 3</script><p>那么如何理解公示(3)呢？</p><p>第一行的disparity就是Network预测的结果。首先，我们需要对disparity做一个转化。由先验知识可知</p><script type="math/tex; mode=display">depth = \frac{bf}{disparity} \tag 4</script><p>可见depth和disparity呈现反比关系。这里使用<code>DispToDepth</code>函数实现转换。</p><p>第二行做了一个前提假设，假设我们拍摄target图像的相机在世界坐标系的原点处。根据《视觉SLAM十四讲》第五讲中所述，三维世界的坐标系可以通过相机的内参矩阵转化为二维坐标。数学描述为</p><script type="math/tex; mode=display">ZP_{uv}= Z\left[\begin{matrix}u\\v\\1\end{matrix}\right]=\left[\begin{matrix}f_x & 0   & c_x \\0   & f_y & c_y \\0   & 0   & 1   \\\end{matrix}\right]\left[\begin{matrix}X \\Y \\Z\\\end{matrix}\right]=KP_w \tag 5</script><p>其中P为世界坐标，u、v为相机坐标。而我们现在有了像素的二维坐标，可以通过<code>np.meshgrid</code>构建。为了得到对应的世界坐标，我们不仅仅需要像素的二维坐标，还需要一个深度。其实，公式(5)可以写成</p><script type="math/tex; mode=display">P_{uv}=\left[\begin{matrix}u\\v\\1\end{matrix}\right]=\left[\begin{matrix}f_x & 0   & c_x \\0   & f_y & c_y \\0   & 0   & 1   \\\end{matrix}\right]\left[\begin{matrix}X/Z \\Y/Z \\1\\\end{matrix}\right]=KP^{'}_w \tag 5</script><p>$P^{‘}_w$称为归一化坐标。归一化坐标可以看成相机前方$z=1$处平面上的坐标。可以看到，如果对归一化坐标同时乘以任何一个数，相机的归一化坐标是完全一样的，说明<strong>深度信息</strong>在单目图像上丢失了。</p><p>深度就是需要通过公式(3)第一行得到的depth了。首先用<code>np.meshgrid</code>得到像素坐标，和内参的逆矩阵相乘得到归一化坐标，归一化坐标乘以深度，就可以得到三维世界坐标系下的坐标（注意这里<strong>假设我们拍摄target图像的相机就是世界坐标系</strong>），即CamPoints。数学描述为</p><script type="math/tex; mode=display">P_w = ZK^{-1}P_{uv} \tag 6</script><p>我们现在有了世界坐标了，接下来让我们移动相机，假设我们简单的把相机平移到原相机位置的右侧，这时候就可以用先验知识求得相机位姿的矩阵$T_{t \rightarrow {t^{‘} } }$。当然，更细节的得到位姿矩阵的方法在<code>transformation_from_parameters</code>函数中实现，需要结合<strong>轴角</strong>和<strong>平移向量</strong>构建。接下来是理解模型是如何监督的重点。我们通过左侧相机的像素坐标得到了每一个像素位置的世界坐标。现在我们需要知道，左侧图像中的每一个像素点所对应在空间中的实际的点，映射到了右侧相机的图片的哪个像素位置。可以继续通过公式(5)变换到像素坐标系下，但这里的右侧相机所在的坐标系已经与标准的世界坐标系有所偏移，所以我们需要做一些小小的修改</p><script type="math/tex; mode=display">P_{u^{'}v^{'} }=\frac{1}{Z}K(RP_w+\vec t)=\frac{1}{Z}KT_{t \rightarrow {t^{'} } }P_w \tag 7</script><p>具体在<code>Project3D</code>中实现。这里得到的新的$P<em>{u^{‘} v^{‘}}$，就是左侧图像像素$P</em>{uv}$所表示的空间点，在右侧图像像素的位置，即右侧图像的$(u’,v’)$处。之后通过sampler采样，得到根据右侧图像重建后的图像$I_{ {t^{ ‘ } } \rightarrow t}$。</p><p>结合图1更好理解</p><p><img src="project3d.jpeg" alt=""></p><center>  Fig. 1 监督过程</center><p>对于重建误差，可以表述为</p><script type="math/tex; mode=display">reconError(I_a,I_b)=\frac{\alpha}{2}(1-SSIM(I_a, I_b)) + (1-\alpha)||I_a - I_b|| \tag 8</script><p>边缘平滑损失定义为</p><script type="math/tex; mode=display">L_s = |\partial_xd^*_t|e^{-|\partial_xI_t|}+|\partial_yd^*_t|e^{-|\partial_yI_t|} \tag 9</script><p>最后总的目标函数为</p><script type="math/tex; mode=display">L = \mu L_p +\lambda L_s \tag{10}</script><h3 id="3-2-自监督学习优化"><a href="#3-2-自监督学习优化" class="headerlink" title="3.2 自监督学习优化"></a>3.2 自监督学习优化</h3><p><img src="monodepth2model.png" alt=""></p><center>  Fig. 2 (a)深度预测网络。(b)相机位姿网络。(c)最小重建投影误差。(d)多尺度估计。</center><h4 id="3-2-1-逐像素最小重建投影误差"><a href="#3-2-1-逐像素最小重建投影误差" class="headerlink" title="3.2.1 逐像素最小重建投影误差"></a>3.2.1 逐像素最小重建投影误差</h4><p><strong>Problematic pixels</strong>可以分为两类，一种是超出图像边界的像素(<strong>Out of view pixels</strong>)，另一种是遮挡像素(<strong>Occluded pixels</strong>)。超出图像边界的像素可以通过掩盖这些像素的误差，即不计入误差累计。但并没有解决遮挡像素的问题。</p><p>计算重建投影误差的时候，之前的一些方法都是把不同源图像与目标图像的误差平均。这种情况下，如果网络预测出目标图像的某一个像素点A正确的深度，经过源图像的采样后，重建出的像素点可能会像图2的(c)的$I_{t-1}$所示，导致采样到了遮挡像素的部位，从而造成对应位置像素值差别很大，对结果造成一定的影响。所以相较于公式(1)，该工作做了如下改进</p><script type="math/tex; mode=display">L_p = min(reconError(I_t, I_{ {t^{'} } \rightarrow t}) \tag{11})</script><p><img src="Monodepth2Loss.png" alt="Screenshot 2022-11-16 at 13.00.20"></p><center>  Fig. 3 最小重建投影误差。每个像素都会根据其最匹配的源图像进行计算。图中L画圈部位在R中属于遮挡像素，但可以在-1中找到相匹配的像素点。本质而言是充分的利用了不同源图像的信息。</center><p>这种改进可以将超出边界的像素和遮挡像素问题一举解决，且可以见效图片边界的瑕疵、提升遮挡边界的清晰度并且可以提高精度。</p><h4 id="3-2-2-静态像素自动掩码"><a href="#3-2-2-静态像素自动掩码" class="headerlink" title="3.2.2 静态像素自动掩码"></a>3.2.2 静态像素自动掩码</h4><p>自监督学习的一个前提假设是，场景是静止的，相机是运动的。当相机是静止的或场景中有运动的物体时，性能就会受到很大的影响（测试时会产生黑洞）。一个很简单的想法就是，把这一帧到下一帧中不变的像素点掩盖。同于先前的工作，也是将每个像素点加入掩码算子$\mu$。但不同的是，先前工作需要通过学习得到$\mu$，而该工作是通过前向传播过程自动计算得到，且只有0和1两个值。观察得到，如果在相邻两帧中像素点保持相同会有三种情况：第一种是相机静止；第二种是物体和相机保持同样的速度和方向，相对静止；第三种是低纹理区域。</p><h4 id="3-2-3-多尺度估计"><a href="#3-2-3-多尺度估计" class="headerlink" title="3.2.3 多尺度估计"></a>3.2.3 多尺度估计</h4><p>之前工作的多尺度估计都是在不同size之下计算好误差，最后平均。而这样会倾向于在大面积的low-texture区域产生黑洞，也会造成瑕疵。因此该工作将不同size的预测的图片resize到原始图片的大小，在相同的尺度下进行计算。</p><h3 id="3-3-其他考虑"><a href="#3-3-其他考虑" class="headerlink" title="3.3 其他考虑"></a>3.3 其他考虑</h3><p>网络的baseline采用U-net的encoder，decoder架构，加入了跳层连接，以便更好的结合深度特征信息和局部特征。使用ResNet18作为encoder，包含11M参数量，并且采用了ImageNet上预训练好的权重，实验表明预训练的结果要比从一开始训练的结果要好。网络的decoder采用和Unsupervised monocular depth estimation with left- right consistency中的类似，但最后一层加入sigmoid输出，其他采用ELU作为激活函数。Decoder中用反射padding代替zero-padding，实验表明效果不错。</p><p>对于姿态网络，网络输出轴角和平移向量，并缩放0.01。</p><p>数据增强的概率为50%，策略为水平翻转、随机亮度、对比度、饱和度以及hue jitter。所有输入网络的图片都会用相同的参数进行增强。</p><p>网络用pytorch实现，优化器为Adam，epoch为20，batchsize为12，输入输出默认为640x192。前15epoch用0.0001学习率，最后五个为0.00001。平滑$\lambda$为0.001。 </p><h3 id="3-4-数据集"><a href="#3-4-数据集" class="headerlink" title="3.4 数据集"></a>3.4 数据集</h3><h2 id="4-源码解析"><a href="#4-源码解析" class="headerlink" title="4. 源码解析"></a>4. 源码解析</h2><h3 id="4-1-layers-py"><a href="#4-1-layers-py" class="headerlink" title="4.1 layers.py"></a>4.1 layers.py</h3><p><code>layers.py</code>文件是Monodepth2中最为核心的一个文件，其中包含了以下几种函数：</p><blockquote><p><code>disp_to_dpeth(disp, min_depth, max_depth)</code>：它会将网络的simoid输出转化为预测的深度，这里是运用了深度和视察的先验关系。</p><p><code>transformation_from_parameters(axisangle, translation, invert)</code>：根据poseNet预测出的角度和平移量，计算4x4的转换矩阵。</p><p><code>rot_from_axisangle(vec)</code>：根据坐标轴的欧拉角，得到4x4的旋转矩阵。</p><p><code>get_translation_matrix(translation_vector)</code>：把预测出的平移量转化为4x4的平移矩阵。</p><p><code>upsample(x)</code>：将输入的张量用最邻近差值实现上采样。</p><p><code>get_smooth_loss(disp, img)</code>：计算视差图的平滑度。</p><p><code>compute_depth_errors(gt, pred)</code>：计算预测出的深度图片和GT的各项衡量指标的值。</p></blockquote><p>包含以下层：</p><blockquote><p>Conv3x3：3x3卷积计算单元。</p><p>BackprojectDepth：根据预测的深度、相机坐标系下的坐标和相机内参矩阵的逆矩阵，计算空间坐标系的矩阵（4维度，最后一维度为1，表示三维空间的点）。</p><p>Project3D：根据转换矩阵T和相机内参矩阵K，以及三维空间坐标，计算得到对应相机坐标系下的坐标。</p><p>SSIM：结构相似性计算层。</p></blockquote><h4 id="disp-to-depth"><a href="#disp-to-depth" class="headerlink" title="disp_to_depth"></a>disp_to_depth</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">disp_to_depth</span><span class="token punctuation">(</span>disp<span class="token punctuation">,</span> min_depth<span class="token punctuation">,</span> max_depth<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Convert network's sigmoid output into depth prediction    The formula for this conversion is given in the 'additional considerations'    section of the paper.    """</span>    <span class="token comment"># 将预测得到的视差通过min_depth和max_depth的限制，得到对应范围内的深度图</span>    <span class="token comment"># TODO: we know that disp = f*b / depth, but in this function, where are f and b?</span>    min_disp <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> max_depth    max_disp <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> min_depth    scaled_disp <span class="token operator">=</span> min_disp <span class="token operator">+</span> <span class="token punctuation">(</span>max_disp <span class="token operator">-</span> min_disp<span class="token punctuation">)</span> <span class="token operator">*</span> disp    depth <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> scaled_disp    <span class="token keyword">return</span> scaled_disp<span class="token punctuation">,</span> depth<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="transformation-from-parameters"><a href="#transformation-from-parameters" class="headerlink" title="transformation_from_parameters"></a>transformation_from_parameters</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">transformation_from_parameters</span><span class="token punctuation">(</span>axisangle<span class="token punctuation">,</span> translation<span class="token punctuation">,</span> invert<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Convert the network's (axisangle, translation) output into a 4x4 matrix     一般而言，对于一个坐标，可以通过旋转矩阵R和平移向量t来变换到另一个坐标     但是也可以将R和t写作齐次式，M     函数的输入是欧拉角，需要调用 rot_from_axisangle将欧拉角转化为旋转矩阵     另一个输入是平移向量，需要调用get_translation_matrix将向量转化为平移矩阵     最后将两个矩阵结合即可    """</span>    R <span class="token operator">=</span> rot_from_axisangle<span class="token punctuation">(</span>axisangle<span class="token punctuation">)</span>    t <span class="token operator">=</span> translation<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> invert<span class="token punctuation">:</span>        R <span class="token operator">=</span> R<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        t <span class="token operator">*=</span> <span class="token operator">-</span><span class="token number">1</span>    T <span class="token operator">=</span> get_translation_matrix<span class="token punctuation">(</span>t<span class="token punctuation">)</span>    <span class="token keyword">if</span> invert<span class="token punctuation">:</span>        M <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>R<span class="token punctuation">,</span> T<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        M <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>T<span class="token punctuation">,</span> R<span class="token punctuation">)</span>    <span class="token keyword">return</span> M<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="rot-from-axisangle"><a href="#rot-from-axisangle" class="headerlink" title="rot_from_axisangle"></a>rot_from_axisangle</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">rot_from_axisangle</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Convert an axisangle rotation into a 4x4 transformation matrix    (adapted from https://github.com/Wallacoloo/printipi)    Input 'vec' has to be Bx1x3    """</span>    angle <span class="token operator">=</span> torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>vec<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>    axis <span class="token operator">=</span> vec <span class="token operator">/</span> <span class="token punctuation">(</span>angle <span class="token operator">+</span> <span class="token number">1e-7</span><span class="token punctuation">)</span>    ca <span class="token operator">=</span> torch<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>angle<span class="token punctuation">)</span>    sa <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>angle<span class="token punctuation">)</span>    C <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> ca    x <span class="token operator">=</span> axis<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> axis<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    z <span class="token operator">=</span> axis<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    xs <span class="token operator">=</span> x <span class="token operator">*</span> sa    ys <span class="token operator">=</span> y <span class="token operator">*</span> sa    zs <span class="token operator">=</span> z <span class="token operator">*</span> sa    xC <span class="token operator">=</span> x <span class="token operator">*</span> C    yC <span class="token operator">=</span> y <span class="token operator">*</span> C    zC <span class="token operator">=</span> z <span class="token operator">*</span> C    xyC <span class="token operator">=</span> x <span class="token operator">*</span> yC    yzC <span class="token operator">=</span> y <span class="token operator">*</span> zC    zxC <span class="token operator">=</span> z <span class="token operator">*</span> xC    rot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>vec<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>vec<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>x <span class="token operator">*</span> xC <span class="token operator">+</span> ca<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>xyC <span class="token operator">-</span> zs<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>zxC <span class="token operator">+</span> ys<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>xyC <span class="token operator">+</span> zs<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>y <span class="token operator">*</span> yC <span class="token operator">+</span> ca<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>yzC <span class="token operator">-</span> xs<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>zxC <span class="token operator">-</span> ys<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>yzC <span class="token operator">+</span> xs<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>z <span class="token operator">*</span> zC <span class="token operator">+</span> ca<span class="token punctuation">)</span>    rot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    <span class="token keyword">return</span> rot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="get-translation-matrix"><a href="#get-translation-matrix" class="headerlink" title="get_translation_matrix"></a>get_translation_matrix</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_translation_matrix</span><span class="token punctuation">(</span>translation_vector<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Convert a translation vector into a 4x4 transformation matrix    """</span>    T <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>translation_vector<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>translation_vector<span class="token punctuation">.</span>device<span class="token punctuation">)</span>    <span class="token comment"># 转为列向量</span>    t <span class="token operator">=</span> translation_vector<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    T<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    T<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    T<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    T<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>    <span class="token comment"># 给T矩阵最后一列的前三个赋值为列向量t</span>    T<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">=</span> t    <span class="token keyword">return</span> T<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="get-smooth-loss"><a href="#get-smooth-loss" class="headerlink" title="get_smooth_loss"></a>get_smooth_loss</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_smooth_loss</span><span class="token punctuation">(</span>disp<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Computes the smoothness loss for a disparity image    The color image is used for edge-aware smoothness    """</span>    <span class="token comment"># 计算x方向的视差的梯度</span>    grad_disp_x <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>disp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> disp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 计算y方向的视差的梯度</span>    grad_disp_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>disp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> disp<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    grad_img_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    grad_img_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">-</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    grad_disp_x <span class="token operator">*=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>grad_img_x<span class="token punctuation">)</span>    grad_disp_y <span class="token operator">*=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>grad_img_y<span class="token punctuation">)</span>    <span class="token keyword">return</span> grad_disp_x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> grad_disp_y<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="BackprojectDepth"><a href="#BackprojectDepth" class="headerlink" title="BackprojectDepth"></a>BackprojectDepth</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BackprojectDepth</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""将预测得到的depth图转化为3维的点云图片    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>BackprojectDepth<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size        self<span class="token punctuation">.</span>height <span class="token operator">=</span> height        self<span class="token punctuation">.</span>width <span class="token operator">=</span> width        <span class="token comment"># 根据宽度和高度，生成对应的行列坐标，会得到[列坐标2维矩阵，行坐标2维矩阵]这样一个list</span>        meshgrid <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>width<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>height<span class="token punctuation">)</span><span class="token punctuation">,</span> indexing<span class="token operator">=</span><span class="token string">'xy'</span><span class="token punctuation">)</span>        <span class="token comment"># 把list按照第一维度堆叠起来，生成shape为[2, width, height]的id_coords</span>        self<span class="token punctuation">.</span>id_coords <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>meshgrid<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>id_coords <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>id_coords<span class="token punctuation">)</span><span class="token punctuation">,</span>                                      requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ones <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>height <span class="token operator">*</span> self<span class="token punctuation">.</span>width<span class="token punctuation">)</span><span class="token punctuation">,</span>                                 requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        <span class="token comment"># 将id_coords的列坐标和行坐标先打平为[1, width*height]，堆叠为[2, width*height]，扩充为[1,           # 2, width*height]</span>        self<span class="token punctuation">.</span>pix_coords <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>            <span class="token punctuation">[</span>self<span class="token punctuation">.</span>id_coords<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>id_coords<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment"># 按照batch_size堆叠</span>        self<span class="token punctuation">.</span>pix_coords <span class="token operator">=</span> self<span class="token punctuation">.</span>pix_coords<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 将1张量与坐标结合，这样形成[1, 3, width*height]的张量，每一列就代表一个[x, y, 1]二维坐标</span>        self<span class="token punctuation">.</span>pix_coords <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>pix_coords<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ones<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                       requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> depth<span class="token punctuation">,</span> inv_K<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""            u   fx  0   cx     X/Z            v = 0   fy  cy  .  Y/Z            1   0   0   1      1            pix_coords = K . cam_points            cam_points = K-1 . pix_coords        """</span>        cam_points <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>inv_K<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>pix_coords<span class="token punctuation">)</span>        <span class="token comment"># 上一行得到的cam_points，本质上是在归一化平面上的，此时Z即深度信息是丢失的，这也是</span>        <span class="token comment"># 单目图像无法得到3维图像的原因。但这里的depth是经过神经网络预测得到的，因此对于归一化</span>        <span class="token comment"># 平面上的坐标[X/Z, Y/Z, 1]同时乘各个点的深度，就能得到[X, Y, Z]</span>        cam_points <span class="token operator">=</span> depth<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> cam_points        <span class="token comment"># [X, Y, Z] -> [X, Y, Z, 1]</span>        cam_points <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>cam_points<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ones<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> cam_points<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Project3D"><a href="#Project3D" class="headerlink" title="Project3D"></a>Project3D</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Project3D</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Layer which projects 3D points into a camera with intrinsics K and at position T    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Project3D<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> batch_size        self<span class="token punctuation">.</span>height <span class="token operator">=</span> height        self<span class="token punctuation">.</span>width <span class="token operator">=</span> width        self<span class="token punctuation">.</span>eps <span class="token operator">=</span> eps    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> points<span class="token punctuation">,</span> K<span class="token punctuation">,</span> T<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 传入的points为世界坐标系下的坐标[X, Y, Z, 1]</span>        <span class="token comment"># K为相机内参，T为转换矩阵</span>        M <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>K<span class="token punctuation">,</span> T<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token comment"># 相机坐标系下的坐标 = K (RP+t) = KTP</span>        cam_points <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>M<span class="token punctuation">,</span> points<span class="token punctuation">)</span>        <span class="token comment"># 除去Z，eps是为了防止除0导致的错误</span>        pix_coords <span class="token operator">=</span> cam_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>cam_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span>        <span class="token comment"># 从[batch, 2, width*height]转换为[batch, 2, height, width]</span>        pix_coords <span class="token operator">=</span> pix_coords<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>height<span class="token punctuation">,</span> self<span class="token punctuation">.</span>width<span class="token punctuation">)</span>        <span class="token comment"># [batch, 2, height, width] -> [batch, height, width, 2]</span>        pix_coords <span class="token operator">=</span> pix_coords<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 归一化到0-1之间</span>        pix_coords<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/=</span> self<span class="token punctuation">.</span>width <span class="token operator">-</span> <span class="token number">1</span>        pix_coords<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/=</span> self<span class="token punctuation">.</span>height <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment"># 移动到[-1, 1]之间</span>        pix_coords <span class="token operator">=</span> <span class="token punctuation">(</span>pix_coords <span class="token operator">-</span> <span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span>        <span class="token keyword">return</span> pix_coords<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Paper Reading Note </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Structural SIMilarity Index</title>
      <link href="/2022/11/10/SSIM/"/>
      <url>/2022/11/10/SSIM/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Over-all-Purpose"><a href="#1-Over-all-Purpose" class="headerlink" title="1. Over all Purpose"></a>1. Over all Purpose</h2><p>The luminance information computation method is:</p><script type="math/tex; mode=display">Lumination = illumination\times reflectance \tag 1</script><p>However, based on our prior knowledge</p><blockquote><p><strong>The structures of the objects in the scene are independent of the illumination.</strong></p></blockquote><p>Then we can define the structural information in an image as those attributes that represent the structure of objects in the scene. (Since luminance and contrast can vary across a scene, we can use the local luminance and contrast.)</p><h2 id="2-System-Diagram"><a href="#2-System-Diagram" class="headerlink" title="2. System Diagram"></a>2. System Diagram</h2><p><img src="SSIMDiagram.png" alt="SSIM"></p><center>  Fig. 1 Diagram of the structural similarity (SSIM) measurement system.</center><p>The system separates the task of similarity measurement into three comparisons: <strong>luminance</strong>, <strong>contrast</strong> and <strong>structure</strong>.</p><h2 id="3-Details"><a href="#3-Details" class="headerlink" title="3. Details"></a>3. Details</h2><h3 id="Three-Important-conditions"><a href="#Three-Important-conditions" class="headerlink" title="Three Important conditions"></a>Three Important conditions</h3><ol><li>Symmetry: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="16.274ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7192.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(645,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1034,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1606,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2050.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2540.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3207.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(4263.2,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(4908.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5297.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5787.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(6231.9,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6803.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>;</li><li>Boundedness: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.777ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4763.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(645,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1034,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1606,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2050.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2540.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3207.4,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(4263.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>;</li><li>Unique maximum: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="10.777ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4763.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mo" transform="translate(645,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1034,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(1606,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2050.7,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2540.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3207.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4263.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> if and only if <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="5.42ex" height="1.783ex" role="img" focusable="false" viewBox="0 -583 2395.6 788"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(849.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(1905.6,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>;</li></ol><h3 id="Luminance-Measurement"><a href="#Luminance-Measurement" class="headerlink" title="Luminance Measurement"></a>Luminance Measurement</h3><script type="math/tex; mode=display">\mu_x = \frac{1}{N}\sum_{i=1}^Nx_i \tag 2</script><h3 id="Luminace-Comparison"><a href="#Luminace-Comparison" class="headerlink" title="Luminace Comparison"></a>Luminace Comparison</h3><script type="math/tex; mode=display">l(x, y)=\frac{2\mu_x\mu_y+C_1}{\mu_x^2+\mu_y^2+C_1} \tag 3</script><p>where the constance <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="2.605ex" height="1.934ex" role="img" focusable="false" viewBox="0 -705 1151.6 855"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></svg></mjx-container> is included to avoid instability when <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.887ex;" xmlns="http://www.w3.org/2000/svg" width="7.585ex" height="2.774ex" role="img" focusable="false" viewBox="0 -833.9 3352.5 1225.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mn" transform="translate(636,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(636,-247) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1312.7,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="msubsup" transform="translate(2312.9,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mn" transform="translate(636,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(636,-247) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container> is very close to zero.</p><script type="math/tex; mode=display">C_1 = (K_1L)^2 \tag 4</script><p>where <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="1.541ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 681 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g></g></g></svg></mjx-container> is the dynamic range of the pixel values, and <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.339ex;" xmlns="http://www.w3.org/2000/svg" width="8.817ex" height="1.885ex" role="img" focusable="false" viewBox="0 -683 3897.1 833"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mn" transform="translate(882,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(1563.3,0)"><g data-mml-node="text"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="text" transform="translate(778,0)"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g></g><g data-mml-node="mn" transform="translate(3397.1,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container> is a small constant.</p><h3 id="Contrast-Measurement"><a href="#Contrast-Measurement" class="headerlink" title="Contrast Measurement"></a>Contrast Measurement</h3><p>Remove the intensity from the signal. So in discrete form, the resulting signal <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="6.527ex" height="1.808ex" role="img" focusable="false" viewBox="0 -583 2884.9 799"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(794.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="msub" transform="translate(1794.4,0)"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g><g data-mml-node="mi" transform="translate(636,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container> corresponds to the projection of vector <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.294ex" height="1.025ex" role="img" focusable="false" viewBox="0 -442 572 453"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></svg></mjx-container> onto the hyperplane defined by</p><script type="math/tex; mode=display">\sum_{i=1}^Nx_i = 0 \tag 5</script><p>Use the standard deviation as an estimate of the contrast (unbiased estimate)</p><script type="math/tex; mode=display">\sigma_x = (\frac{1}{N-1}\sum_{i=1}^N(x_i - \mu_x)^2)^{1/2} \tag 6</script><h3 id="Contrast-Comparison"><a href="#Contrast-Comparison" class="headerlink" title="Contrast Comparison"></a>Contrast Comparison</h3><script type="math/tex; mode=display">c(x,y)=\frac{2\sigma_x\sigma_y+C_2}{\sigma_x^2+\sigma_y^2+C_2} \tag 7</script><script type="math/tex; mode=display">C_2 = (K_2L)^2 \tag 8</script><h3 id="Structure-Comparison"><a href="#Structure-Comparison" class="headerlink" title="Structure Comparison"></a>Structure Comparison</h3><script type="math/tex; mode=display">s(x,y) = \frac{\sigma_{xy}+C_3}{\sigma_x\sigma_y+C_3} \tag 9</script><script type="math/tex; mode=display">\sigma_{xy} = \frac{1}{N - 1}\sum_{i=1}^N(x_i - \mu_x)(y_i-\mu_y) \tag {10}</script><h3 id="SSIM"><a href="#SSIM" class="headerlink" title="SSIM"></a>SSIM</h3><script type="math/tex; mode=display">SSIM(x,y) = [l(x,y)]^{\alpha}\cdot[c(x,y)]^{\beta}\cdot[s(x,y)]^{\gamma}</script><p>Where <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.031ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 5317.8 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FC" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path></g><g data-mml-node="mo" transform="translate(917.8,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1973.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(2473.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2918.2,0)"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mo" transform="translate(3762,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(4817.8,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container>, and <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.489ex;" xmlns="http://www.w3.org/2000/svg" width="5.377ex" height="1.995ex" role="img" focusable="false" viewBox="0 -666 2376.6 882"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D6FE" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path></g><g data-mml-node="mo" transform="translate(820.8,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(1876.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></svg></mjx-container> are parameters used to adjust the relative importance of the three components.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Paper Reading Note </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
